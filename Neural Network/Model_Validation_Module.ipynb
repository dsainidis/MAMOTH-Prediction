{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nonprofit-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "import datetime\n",
    "from ipynb.fs.defs.Neural_Network_Module import Dataset, transformations, train_nn, prediction\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "binding-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_dist(actual, predictions, model_type, case=''):\n",
    "    \"\"\"Prints the error distribution plot\n",
    "    Parameters\n",
    "    --------\n",
    "    actual : pd.Series\n",
    "        A Series with the actual class of each prediction\n",
    "        \n",
    "    predictions : pd.Series\n",
    "        A Series with the predicted class of each prediction\n",
    "        \n",
    "    model_type : str\n",
    "        Could be 'class_regression' or 'mosquito_regression' or 'classification'\n",
    "    \n",
    "    case: str, optional\n",
    "        Title of the plot (default= '')\n",
    "    \"\"\"\n",
    "    error = np.abs(actual-predictions).tolist()\n",
    "    if model_type != 'mosquito_regression':\n",
    "        bins = np.arange(len(actual.unique())) - 0.5\n",
    "        plt.hist(error, bins)\n",
    "        plt.xticks(range(len(actual.unique())))\n",
    "    else:\n",
    "        plt.hist(error)\n",
    "    plt.xlabel('abs(error)')\n",
    "    plt.title('Error Distribution \\n' + case)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "written-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(actual, predictions, model_type, case=''):\n",
    "    \"\"\"Prints the histogram of the actual values and the predicted values\n",
    "    Parameters\n",
    "    --------\n",
    "    actual : pd.Series\n",
    "        A Series with the actual class of each prediction\n",
    "        \n",
    "    predictions : pd.Series\n",
    "        A Series with the predicted class of each prediction\n",
    "        \n",
    "    model_type : str\n",
    "        Could be 'class_regression' or 'mosquito_regression' or 'classification'\n",
    "    \n",
    "    case: str, optional\n",
    "        Title of the plot (default= '')\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,8)) \n",
    "    if model_type != 'mosquito_regression':\n",
    "        bins = np.arange(len(actual.unique())+1)-0.5\n",
    "        plt.hist(actual, bins=bins, alpha=0.5, label='actual')\n",
    "        plt.hist(predictions, bins=bins, alpha=0.5, label='prediction')\n",
    "        plt.xticks(range(len(actual.unique())))\n",
    "    else:\n",
    "        plt.hist(actual, alpha=0.5, label='actual')\n",
    "        plt.hist(predictions, alpha=0.5, label='prediction')\n",
    "    plt.legend()\n",
    "    plt.title('Histogram of actual vs predicted values \\n'+case)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "educated-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_per_class(test, case=''):\n",
    "    \"\"\"Prints the error distribution per class plot\n",
    "    Parameters\n",
    "    --------\n",
    "    actual : lst\n",
    "        A list with the actual class of each prediction\n",
    "        \n",
    "    case: str, optional\n",
    "        Title of the plot (Area and mosquito genus) (default= '')\n",
    "    \"\"\"\n",
    "    labels = test.loc[:,'actual'].unique().tolist()\n",
    "    labels.sort()\n",
    "    f = []\n",
    "    length = []\n",
    "    for k in labels:\n",
    "        cc = test.loc[test['actual']==k]\n",
    "        length.append(len(cc))\n",
    "        actual = cc.loc[:,'actual']\n",
    "        predictions = cc.loc[:,'prediction']\n",
    "        mae_class = mean_absolute_error(actual, predictions)\n",
    "        f.append(mae_class)\n",
    "    labels = [str(int(e)) for e in labels]\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.bar(labels,f)\n",
    "    for i, v in enumerate(f):\n",
    "        ax.text(i, v, str('%.2f'%(v)), rotation=30)\n",
    "        ax.text(i, v/2,'n = '+ str(length[i]), weight=\"bold\", ha='center', rotation=90)\n",
    "    plt.xlabel('class')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('MAE per class ' + case)\n",
    "    plt.show()\n",
    "    \n",
    "    print('-----------|class error-MAE| difference-----------')\n",
    "    z = np.abs(f-mean_absolute_error(actual, predictions))\n",
    "    print('mean:',z.mean())\n",
    "    print('std:',z.std())\n",
    "    print('coefficient of variation (std/mean):',z.std()/z.mean())\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print('----------normalized difference-------------')\n",
    "    min_val = min(z)\n",
    "    max_val = max(z)\n",
    "    z = (z - min_val) / (max_val-min_val)\n",
    "    print('mean:',z.mean())\n",
    "    print('std:',z.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "expired-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_per_month(df, case=''):\n",
    "    \"\"\"Prints the error per month\n",
    "    Parameters\n",
    "    --------\n",
    "    df : dataframe\n",
    "        A dataframe containing the data\n",
    "    \n",
    "    case: str, optional\n",
    "        Title of the plot (Area and mosquito genus) (default= '')\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    labels = (df['dt_prediction'].dt.month).unique()\n",
    "    labels.sort()\n",
    "    labels = [str(e) for e in labels]\n",
    "    df['abs(error)'] = np.abs(df['actual']-df['prediction'])\n",
    "    f = df.groupby(by=[df['dt_prediction'].dt.month])['abs(error)'].mean().values\n",
    "    length = df.groupby(by=[df['dt_prediction'].dt.month])['dt_prediction'].count().values\n",
    "    ax.bar(labels,f)\n",
    "    for i, v in enumerate(f):\n",
    "        ax.text(i, v, str('%.2f'%(v)),rotation=30)\n",
    "        ax.text(i, v/2,'n = '+ str(length[i]),weight=\"bold\",ha='center', rotation=90)\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('Mean Absolute Error per month ' + case)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "formed-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot_error(actual, prediction, case=''):\n",
    "    \"\"\"Prints the error in relation with the distance of point from the train region\n",
    "    Parameters\n",
    "    --------\n",
    "    df : dataframe\n",
    "        A dataframe containing the data\n",
    "    \n",
    "    case: str, optional\n",
    "        Title of the plot (Area and mosquito genus) (default= '')\n",
    "    \"\"\"\n",
    "    # choose the input and output variables\n",
    "    x, y = actual, np.abs(actual-prediction)\n",
    "    plt.scatter(x, y)\n",
    "    plt.xlabel('Mosquito bins')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title('Scatterplot of error ' + case)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf2b6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_per_group(actual,prediction,case=''):\n",
    "    \"\"\"Prints the error distribution plot\n",
    "    Parameters\n",
    "    --------\n",
    "    actual : pd.Series\n",
    "        A Series with the actual class of each prediction\n",
    "        \n",
    "    predictions : pd.Series\n",
    "        A Series with the predicted class of each prediction\n",
    "        \n",
    "    case: str, optional\n",
    "        Title of the plot (default= '')\n",
    "\n",
    "    \"\"\"\n",
    "    test = {'mosq_now':actual,'predictions':prediction}\n",
    "    test = pd.DataFrame(test)\n",
    "    test['classes'] = pd.cut(x=test['mosq_now'], bins=[-1, 100, 200, 300, 400, 500, np.inf],\n",
    "                      labels=['0-100', '101-200', '201-300', '301-400', '401-500', '500<'])\n",
    "    labels = test['classes'].unique().tolist()\n",
    "    labels.sort()\n",
    "    f = []\n",
    "    length = []\n",
    "    for k in labels:\n",
    "        cc = test.loc[test['classes']==k]\n",
    "        length.append(len(cc))\n",
    "        actual = cc.loc[:,'mosq_now']\n",
    "        predictions = cc.loc[:,'predictions']\n",
    "        f.append(mean_absolute_error(actual, predictions))\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.bar(labels,f)\n",
    "    for i, v in enumerate(f):\n",
    "        ax.text(i, v, str('%.2f'%(v)),rotation=30)\n",
    "        ax.text(i, v/2,'n = '+ str(length[i]),weight=\"bold\",ha='center', rotation=90)\n",
    "    plt.xlabel('Mosquito Group')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('MAE per Mosquito group \\n'+case)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3029f9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_cdf(actual,prediction, case=''):\n",
    "    \"\"\"Prints the cdf of errors\n",
    "    Parameters\n",
    "    --------\n",
    "    actual : pd.Series\n",
    "        A Series with the actual class of each prediction\n",
    "        \n",
    "    predictions : pd.Series\n",
    "        A Series with the predicted class of each prediction\n",
    "        \n",
    "    case: str, optional\n",
    "        Title of the plot (default= '')\n",
    "\n",
    "    \"\"\"\n",
    "    error = np.abs(actual-prediction)\n",
    "    \n",
    "    a = np.sort(error.unique())\n",
    "    b = np.array(error)\n",
    "    cdf = np.zeros(len(a))\n",
    "    for k, val in enumerate(a):\n",
    "        mask_d = b <= val\n",
    "        cdf[k] = mask_d.sum()/ len(b)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.plot(a,cdf)\n",
    "    plt.grid()\n",
    "    plt.xlabel('abs(error)',fontsize=18)\n",
    "    plt.ylabel('CDF',fontsize=18)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    #plt.title('CDF of error \\n' + case)\n",
    "    plt.show() \n",
    "    \n",
    "    b = np.sort(error)\n",
    "    a = np.arange(1,len(error)+1) \n",
    "    cdf = np.zeros(len(a))\n",
    "    for k, val in enumerate(b):\n",
    "        cdf[k] = b[k]\n",
    "    plt.plot(a,cdf)\n",
    "    plt.grid()\n",
    "    plt.xlabel('Number of samples',fontsize=18)\n",
    "    plt.ylabel('Error',fontsize=18)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.title('CDF of error \\n' + case)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8265e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(train, test, threshold=3):\n",
    "    \"\"\"Calculates the perfomance of the model on train and test set\n",
    "    Parameters\n",
    "    --------\n",
    "    train : Dataframe\n",
    "        A Dataframe with the actual and the predicted values on the train set\n",
    "        \n",
    "    test : Dataframe\n",
    "        A Dataframe with the actual and the predicted values on the train set\n",
    "        \n",
    "    threshold: int, optional\n",
    "        A threshold to calculate percentage of error < threshold (default= 3)\n",
    "\n",
    "    \"\"\"    \n",
    "    print('MAE on train set: ', mean_absolute_error(train['actual'], train['prediction']))\n",
    "\n",
    "    print('min prediction:',min(train['prediction']))\n",
    "    print('max prediction:',max(train['prediction']))\n",
    "    \n",
    "    print()\n",
    "\n",
    "    print('MAE on test set: ', mean_absolute_error(test['actual'], test['prediction']))\n",
    "    perc = ((np.abs(test['actual']-test['prediction']) < (threshold+0.5)).mean())*100\n",
    "    print('Error <= '+str(threshold)+':',\"%.2f\"%perc,'%')\n",
    "\n",
    "    print('min prediction:',min(test['prediction']))\n",
    "    print('max prediction:',max(test['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b90e69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(train, test, model_type, case=''):\n",
    "    \"\"\"Prints plots about the performance of the model on the test set\n",
    "    \n",
    "    Parameters\n",
    "    --------        \n",
    "    test : Dataframe\n",
    "        A Dataframe with the actual and the predicted values on the train set\n",
    "    \n",
    "    model_type : str\n",
    "        Could be 'class_regression' or 'mosquito_regression' or 'classification'\n",
    "        \n",
    "    case: str, optional\n",
    "        Title of the plot (default= '')\n",
    "    \"\"\"\n",
    "    if model_type != 'mosquito_regression':\n",
    "        metrics(train, test)\n",
    "        plot_error_per_class(test, case)\n",
    "    else:\n",
    "        metrics(train, test, threshold=30)\n",
    "        plot_error_per_group(test['actual'],test['prediction'], case)\n",
    "        error_cdf(test['actual'],test['prediction'], case)\n",
    "    scatter_plot_error(test['actual'],test['prediction'], case)\n",
    "    plot_error_dist(test['actual'],test['prediction'], model_type, case)\n",
    "    plot_hist(test['actual'],test['prediction'], model_type, case)\n",
    "    plot_error_per_month(test, case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ec0c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_random_split(data, model, test=None, filepath = '', date_col = 'dt_placement',\n",
    "                            fi=False, case='',export=False):\n",
    "    \"\"\"Trains a model on random splitted data\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    data : dataframe\n",
    "        A dataframe containing the data\n",
    "    \n",
    "    model : torch.nn.model\n",
    "        A NN model to train\n",
    "        \n",
    "    embedding_data : dataframe, optional\n",
    "        A datafrane with the categorical features (default = None)\n",
    "        \n",
    "    filepath : srt, optional\n",
    "        The path of the file to export the results (default = '')\n",
    "        \n",
    "    date_col : str, optional\n",
    "        The name of the date column (default = 'dt_placement')\n",
    "        \n",
    "    fi: boolean, optional\n",
    "        If True, prints the feature importance of the model (time consuming process) (default = False)\n",
    "    \n",
    "    case : str, optional\n",
    "        The title of case for the plot (default='')\n",
    "    \n",
    "    export : boolean, optional\n",
    "        Export a csv with the feature importance and a csv with the test data (default = False)\n",
    "    \"\"\"\n",
    "    case = case + \" random validation\"\n",
    "    \n",
    "    if test is None:\n",
    "        np.random.seed(1)\n",
    "        drop_index = np.random.randint(0, len(data), int((len(data)*20)/100))\n",
    "        test = data.iloc[drop_index,:].reset_index(drop=True)\n",
    "        train = data.drop(drop_index).reset_index(drop=True)\n",
    "#     if test is None:\n",
    "#         train, test = train_test_split(data, test_size=0.2, random_state=3)\n",
    "#         train = train.reset_index(drop=True)\n",
    "#         test = test.reset_index(drop=True)\n",
    "    \n",
    "    del train[date_col]\n",
    "    date = test[date_col]\n",
    "    del test[date_col]\n",
    "    \n",
    "    mosq_col = test.columns[-1]\n",
    "    max_val= train.iloc[:,-1].max()\n",
    "    \n",
    "    model_int = copy.deepcopy(model)\n",
    "    \n",
    "    features = None\n",
    "    if fi:\n",
    "        if model.embedding_data is not None:\n",
    "            columns = data.drop(columns=model.embedded_data.columns.tolist()).columns[:-1].tolist()\n",
    "            columns = columns+embedded_data.columns.tolist()\n",
    "            features = columns\n",
    "        else:\n",
    "            features = data.columns[:-1].tolist()\n",
    "    \n",
    "    train_X, train_y, test_X, test_y = transformations(train, test = test, model_type = model.model_type, \n",
    "                                                       embedding_data = model.embedding_data,\n",
    "                                                       transformation_list = model.transformation_list)\n",
    "\n",
    "    training_set = Dataset(train_X, train_y)\n",
    "\n",
    "    testing_set = Dataset(test_X, test_y)\n",
    "\n",
    "    results_train, results_test, _ = train_nn(model = model_int, train_set = training_set, test_set = testing_set,\n",
    "                               features=features, max_val = max_val)\n",
    "    \n",
    "\n",
    "    test[date_col] = date\n",
    "    test['dt_prediction'] = test[date_col] + datetime.timedelta(days=15)\n",
    "    test['prediction'] = results_test['prediction']\n",
    "    test.loc[test['prediction']<0,'prediction'] = 0\n",
    "    test['error'] = test[mosq_col] - test['prediction']\n",
    "    test['abs(error)'] = np.abs(test[mosq_col] - test['prediction'])\n",
    "    \n",
    "    test = test.rename(columns={mosq_col:'actual'})\n",
    "\n",
    "    validation(results_train, test, model_type=model.model_type, case=case)  \n",
    "    \n",
    "    if export:\n",
    "        csv = filepath + case + '.csv'\n",
    "        test.to_csv(csv,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed8881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_KFold(data, model, cv=10, date_col='dt_placement', case=''):\n",
    "    \"\"\"Trains a model on KFold splitted data\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    data : dataframe\n",
    "        A dataframe containing the data\n",
    "    \n",
    "    model : torch.nn.model\n",
    "        A NN model to train\n",
    "        \n",
    "    date_col : str, optional\n",
    "        The name of the date column (default = 'dt_placement')\n",
    "    \"\"\"\n",
    "    \n",
    "    case = case + ' ' +str(cv) +\" fold validation\"\n",
    "    kf = KFold(n_splits=cv, random_state=0, shuffle=True)\n",
    "    \n",
    "    df_train = pd.DataFrame() \n",
    "    df_test = pd.DataFrame()\n",
    "    \n",
    "    for train_index, test_index in kf.split(data):\n",
    "        \n",
    "        model_int = copy.deepcopy(model)\n",
    "        \n",
    "        train = data.iloc[train_index,:].reset_index(drop=True)        \n",
    "        test = data.iloc[test_index,:].reset_index(drop=True)\n",
    "        \n",
    "        del train[date_col]\n",
    "        date = test[date_col]\n",
    "        del test[date_col]\n",
    "        \n",
    "\n",
    "        train_X, train_y, test_X, test_y = transformations(train, test = test, model_type = model.model_type, \n",
    "                                                           embedding_data = model.embedding_data,\n",
    "                                                           transformation_list = model.transformation_list)\n",
    "\n",
    "        training_set = Dataset(train_X, train_y)\n",
    "\n",
    "        testing_set = Dataset(test_X, test_y)\n",
    "\n",
    "        results_train, results_test, _ = train_nn(model = model_int, train_set = training_set, test_set = testing_set,\n",
    "                                   max_val = train.iloc[:,-1].max())\n",
    "                \n",
    "        results_test['dt_prediction'] = date + datetime.timedelta(days=15)\n",
    "        \n",
    "        df_train = pd.concat([df_train, results_train])\n",
    "        df_test = pd.concat([df_test, results_test])\n",
    "        \n",
    "     \n",
    "    validation(df_train, df_test, model_type=model.model_type, case=case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c7951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def operational_validation(data, model, date, filepath ='', date_col='dt_placement', case='', fi=False, export=False):\n",
    "    \"\"\"Trains a model on data of the previous months and evaluates on data of the next month iteratively.\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "     data : dataframe\n",
    "        A dataframe containing the data\n",
    "    \n",
    "    model : torch.nn.model\n",
    "        A NN model to train\n",
    "        \n",
    "    date: str\n",
    "        The date to start the testing process from (format: YYYY-MM-DD)\n",
    "    \n",
    "    embedding_data : dataframe, optional\n",
    "        A datafrane with the categorical features (default = None)\n",
    "    \n",
    "    filepath : srt\n",
    "        The path of the file to export results (default ='')\n",
    "        \n",
    "    date_col : str, optional\n",
    "        The name of the date column (default = 'dt_placement')\n",
    "    \n",
    "    case : str, optional\n",
    "        The title of case for the plot (default ='')\n",
    "    \n",
    "    export : boolean, optional\n",
    "        Export a csv with the feature importance and a csv with the test data (default=False)\n",
    "        \n",
    "    Raise\n",
    "    --------------\n",
    "    ValueError\n",
    "        If date > maximum available date in the dataset\n",
    "        \n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    if (pd.to_datetime(date) > data['dt_placement'].max()):\n",
    "        raise ValueError('date argument given must be before than '+ str(data['dt_placement'].max()))\n",
    "        \n",
    "    mosq_col = data.columns[-1]\n",
    "        \n",
    "    case = case + \" operational validation\"\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    df_train = pd.DataFrame() \n",
    "    df_test = pd.DataFrame() \n",
    "    \n",
    "    months = data.loc[data['dt_placement']>pd.to_datetime(date),'dt_placement'].dt.to_period('M').unique()\n",
    "    months = months.strftime('%Y-%m')\n",
    "    months.sort()\n",
    "    \n",
    "    features = None\n",
    "    if fi:\n",
    "        if model.embedding_data is not None:\n",
    "            columns = data.drop(columns=model.embedded_data.columns.tolist()+[date_col]).columns[:-1].tolist()\n",
    "            columns = columns+embedded_data.columns.tolist()\n",
    "            features = columns\n",
    "        else:\n",
    "            features = data.columns[:-1].tolist()\n",
    "            \n",
    "    model_int = copy.deepcopy(model)\n",
    "        \n",
    "    for i in months:\n",
    "        date1 = i +'-01'\n",
    "        if i.split('-')[1]>='09':\n",
    "            if i.split('-')[1]=='12':\n",
    "                date2 = str(int(i.split('-')[0])+1) +'-01-01'\n",
    "            else:\n",
    "                date2 = i.split('-')[0] + '-' + str(int(i.split('-')[1]) + 1) + '-01'\n",
    "        else:\n",
    "            date2 = i.split('-')[0] + '-0' + str(int(i.split('-')[1]) + 1) + '-01'\n",
    "\n",
    "        train = data.loc[data[date_col] < pd.to_datetime(date1)]\n",
    "        train = train.reset_index(drop=True)\n",
    "        del train[date_col]\n",
    "        \n",
    "        test = data.loc[data[date_col] >= pd.to_datetime(date1)]\n",
    "        test = test.loc[test[date_col] < pd.to_datetime(date2)]\n",
    "        test = test.reset_index(drop=True)\n",
    "        date = test[date_col]\n",
    "        del test[date_col]\n",
    "        \n",
    "        train_X, train_y, test_X, test_y = transformations(train, test = test, model_type = model.model_type,\n",
    "                                                           embedding_data = model.embedding_data)\n",
    "\n",
    "        training_set = Dataset(train_X, train_y)\n",
    "        \n",
    "        testing_set = Dataset(test_X, test_y)\n",
    "\n",
    "        results_train, results_test, _ = train_nn(model = model_int, train_set = training_set, test_set = testing_set,\n",
    "                                                  features=features, max_val = train.iloc[:,-1].max())\n",
    "        \n",
    "        test[date_col] = date\n",
    "        test['dt_prediction'] = test[date_col] + datetime.timedelta(days=15)\n",
    "        test['prediction'] = results_test['prediction']\n",
    "        test.loc[test['prediction']<0,'prediction'] = 0\n",
    "        test['error'] = test[mosq_col] - test['prediction']\n",
    "        test['abs(error)'] = np.abs(test[mosq_col] - test['prediction'])\n",
    "        \n",
    "        df_train = pd.concat([df_train,results_train])\n",
    "        df_test = pd.concat([df_test,test])\n",
    "        \n",
    "    df_test = df_test.rename(columns={mosq_col:'actual'})\n",
    "    \n",
    "    years = df_test['dt_prediction'].dt.to_period('Y').unique()\n",
    "    years = years.strftime('%Y')\n",
    "    years.sort()\n",
    "    for i in years:\n",
    "        print('====================')\n",
    "        print(i)\n",
    "        print('====================')\n",
    "        df_test_year = df_test.loc[df_test['dt_prediction'].dt.year==int(i)].reset_index(drop=True)\n",
    "        validation(df_train, df_test_year, model_type=model.model_type, case=case)\n",
    "    \n",
    "    df_test = df_test.rename(columns={'actual':mosq_col})\n",
    "    \n",
    "    if export:\n",
    "        csv = filepath + case + '.csv'\n",
    "        df_test.to_csv(csv,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da22544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, test, model, filepath = '', date_col = 'dt_placement', case='', fi = False, export=False):\n",
    "    \"\"\"Trains a model on random splitted data\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    data : dataframe\n",
    "        A dataframe containing the data\n",
    "        \n",
    "    embedding_data : dataframe, optional\n",
    "        A datafrane with the categorical features (default = None)\n",
    "        \n",
    "    filepath : srt, optional\n",
    "        The path of the file to export the results (default = '')\n",
    "        \n",
    "    date_col : str, optional\n",
    "        The name of the date column (default = 'dt_placement')\n",
    "    \n",
    "    case : str, optional\n",
    "        The title of case for the plot (default='')\n",
    "    \n",
    "    export : boolean, optional\n",
    "        Export a csv with the feature importance and a csv with the test data (default = False)\n",
    "    \"\"\"\n",
    "    case = case + \" predict\"\n",
    "    \n",
    "    max_val= data.iloc[:,-1].max()\n",
    "    model_int = copy.deepcopy(model)\n",
    "    \n",
    "    del data[date_col]\n",
    "    date = test[date_col]\n",
    "    del test[date_col]\n",
    "    \n",
    "    features = None\n",
    "    if fi:\n",
    "        if model.embedding_data is not None:\n",
    "            columns = data.drop(columns=model.embedded_data.columns.tolist()+[date_col]).columns[:-1].tolist()\n",
    "            columns = columns+embedded_data.columns.tolist()\n",
    "            features = columns\n",
    "        else:\n",
    "            features = data.columns[:-1].tolist()\n",
    "    \n",
    "    train_X, train_y, test_X, test_y = transformations(train, test = test, model_type = model.model_type,\n",
    "                                                       embedding_data = model.embedding_data)\n",
    "\n",
    "    training_set = Dataset(train_X, train_y)\n",
    "\n",
    "    testing_set = Dataset(test_X, test_y)\n",
    "    \n",
    "    results_test = prediction(model_int, train_set, test_set, max_val = max_val, features = features)\n",
    " \n",
    "    \n",
    "    test[date_col] = date\n",
    "    test['dt_prediction'] = test[date_col] + datetime.timedelta(days=15)\n",
    "    test['prediction'] = results_test['prediction']\n",
    "    \n",
    "    if export:\n",
    "        csv = filepath + case + '.csv'\n",
    "        test.to_csv(csv,index=False)\n",
    "    return test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
