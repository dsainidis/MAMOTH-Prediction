{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nonprofit-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "handmade-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    \"\"\"Calculates the average value of a list\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lst : list\n",
    "        A list of numbers\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    avg : float\n",
    "        The average value of the list\n",
    "    \"\"\"\n",
    "    avg = sum(lst) / len(lst)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ancient-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance, names, filepath, case=None, export= False):\n",
    "    \"\"\"Prints the plot of feature importance of the model and creates a .csv file with the frature importance\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    importance : list\n",
    "        A list containing the importnce of each feature\n",
    "        \n",
    "    names : list\n",
    "        A list containing the names of the features\n",
    "    \n",
    "    filepath : srt\n",
    "        The path of the file to export a csv with the importance of the featured\n",
    "        \n",
    "    case: str, optional\n",
    "        Title of the plot (Area and mosquito genus) (default= '')\n",
    "    \n",
    "    export: boolean, optional\n",
    "        Exports a csv with the importance of each figure (default = False)\n",
    "    \"\"\"\n",
    "    #Create arrays from feature importance and feature names\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    #Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "    \n",
    "    if export:\n",
    "        if case != None and case != '':\n",
    "            fi_df.to_csv(filepath + case + ' fi.csv',index=False)\n",
    "        else:\n",
    "            fi_df.to_csv(filepath +'fi.csv',index=False)\n",
    "\n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(10,8))\n",
    "    \n",
    "    #Plot Searborn bar chart\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    \n",
    "    #Add chart labels\n",
    "    plt.title(case)\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature Names')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "binding-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_dist(actual, predictions, model_type, case=''):\n",
    "    \"\"\"Prints the error distribution plot\n",
    "    Parameters\n",
    "    --------\n",
    "    actual : pd.Series\n",
    "        A Series with the actual class of each prediction\n",
    "        \n",
    "    predictions : pd.Series\n",
    "        A Series with the predicted class of each prediction\n",
    "        \n",
    "    model_type : str\n",
    "        Could be 'class_regression' or 'mosquito_regression' or 'classification'\n",
    "    \n",
    "    case: str, optional\n",
    "        Title of the plot (default= '')\n",
    "    \"\"\"\n",
    "    error = np.abs(actual-predictions).tolist()\n",
    "    if model_type == 'class':\n",
    "        bins = np.arange(len(actual.unique())) - 0.5\n",
    "        plt.hist(error, bins)\n",
    "        plt.xticks(range(len(actual.unique())))\n",
    "    else:\n",
    "        plt.hist(error)\n",
    "    plt.xlabel('abs(error)')\n",
    "    plt.title('Error Distribution \\n' + case)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a564578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(actual, predictions, model_type, case=''):\n",
    "    \"\"\"Prints the histogram of the actual values and the predicted values\n",
    "    Parameters\n",
    "    --------\n",
    "    actual : pd.Series\n",
    "        A Series with the actual class of each prediction\n",
    "        \n",
    "    predictions : pd.Series\n",
    "        A Series with the predicted class of each prediction\n",
    "        \n",
    "    model_type : str\n",
    "        Could be 'class_regression' or 'mosquito_regression' or 'classification'\n",
    "    \n",
    "    case: str, optional\n",
    "        Title of the plot (default= '')\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,8)) \n",
    "    if model_type == 'class':\n",
    "        bins = np.arange(len(actual.unique())+1)-0.5\n",
    "        plt.hist(actual, bins=bins, alpha=0.5, label='actual')\n",
    "        plt.hist(predictions, bins=bins, alpha=0.5, label='prediction')\n",
    "        plt.xticks(range(len(actual.unique())))\n",
    "    else:\n",
    "        plt.hist(actual, alpha=0.5, label='actual')\n",
    "        plt.hist(predictions, alpha=0.5, label='prediction')\n",
    "    plt.legend()\n",
    "    plt.title('Histogram of actual vs predicted values \\n'+case)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "educated-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_per_class(test, case=''):\n",
    "    \"\"\"Prints the error distribution per class plot\n",
    "    Parameters\n",
    "    --------\n",
    "    actual : lst\n",
    "        A list with the actual class of each prediction\n",
    "        \n",
    "    case: str, optional\n",
    "        Title of the plot (Area and mosquito genus) (default= '')\n",
    "    \"\"\"\n",
    "    labels = test.loc[:,'actual'].unique().tolist()\n",
    "    labels.sort()\n",
    "    f = []\n",
    "    length = []\n",
    "    for k in labels:\n",
    "        cc = test.loc[test['actual']==k]\n",
    "        length.append(len(cc))\n",
    "        actual = cc.loc[:,'actual']\n",
    "        predictions = cc.loc[:,'prediction']\n",
    "        mae_class = mean_absolute_error(actual, predictions)\n",
    "        f.append(mae_class)\n",
    "    labels = [str(int(e)) for e in labels]\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.bar(labels,f)\n",
    "    for i, v in enumerate(f):\n",
    "        ax.text(i, v, str('%.2f'%(v)),rotation=30)\n",
    "        ax.text(i, v/2,'n = '+ str(length[i]),weight=\"bold\",ha='center')\n",
    "    plt.xlabel('class')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('MAE per class ' + case)\n",
    "    plt.show()\n",
    "    \n",
    "    print('-----------|class error-MAE| difference-----------')\n",
    "    z = np.abs(f-mean_absolute_error(actual, predictions))\n",
    "    print('mean:',z.mean())\n",
    "    print('std:',z.std())\n",
    "    print('coefficient of variation (std/mean):',z.std()/z.mean())\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print('----------normalized difference-------------')\n",
    "    min_val = min(z)\n",
    "    max_val = max(z)\n",
    "    z = (z - min_val) / (max_val-min_val)\n",
    "    print('mean:',z.mean())\n",
    "    print('std:',z.std())\n",
    "    print('coefficient of variation (std/mean):',z.std()/z.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "expired-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_per_month(df, case=''):\n",
    "    \"\"\"Prints the error per month\n",
    "    Parameters\n",
    "    --------\n",
    "    df : dataframe\n",
    "        A dataframe containing the data\n",
    "    \n",
    "    case: str, optional\n",
    "        Title of the plot (Area and mosquito genus) (default= '')\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    labels = (df['dt_prediction'].dt.month).unique()\n",
    "    labels.sort()\n",
    "    labels = [str(e) for e in labels]\n",
    "    df['abs(error)'] = np.abs(df['actual']-df['prediction'])\n",
    "    f = df.groupby(by=[df['dt_prediction'].dt.month])['abs(error)'].mean().values\n",
    "    length = df.groupby(by=[df['dt_prediction'].dt.month])['dt_prediction'].count().values\n",
    "    ax.bar(labels,f)\n",
    "    for i, v in enumerate(f):\n",
    "        ax.text(i, v, str('%.2f'%(v)),rotation=30)\n",
    "        ax.text(i, v/2,'n = '+ str(length[i]),weight=\"bold\",ha='center')\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('Mean Absolute Error per month ' + case)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "formed-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot_error(actual, prediction, case=''):\n",
    "    \"\"\"Prints the error in relation with the distance of point from the train region\n",
    "    Parameters\n",
    "    --------\n",
    "    df : dataframe\n",
    "        A dataframe containing the data\n",
    "    \n",
    "    case: str, optional\n",
    "        Title of the plot (Area and mosquito genus) (default= '')\n",
    "    \"\"\"\n",
    "    # choose the input and output variables\n",
    "    x, y = actual, np.abs(actual-prediction)\n",
    "    plt.scatter(x, y)\n",
    "    plt.xlabel('Mosquito bins')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title('Scatterplot of error ' + case)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a61b7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_per_group(actual,prediction,case=''):\n",
    "    \"\"\"Prints the error distribution plot\n",
    "    Parameters\n",
    "    --------\n",
    "    actual : pd.Series\n",
    "        A Series with the actual class of each prediction\n",
    "        \n",
    "    predictions : pd.Series\n",
    "        A Series with the predicted class of each prediction\n",
    "        \n",
    "    case: str, optional\n",
    "        Title of the plot (default= '')\n",
    "\n",
    "    \"\"\"\n",
    "    test = {'mosq_bins(t+1)':actual,'predictions':prediction}\n",
    "    test = pd.DataFrame(test)\n",
    "    test['classes'] = pd.cut(x=test['mosq_bins(t+1)'], bins=[-1, 100, 200, 300, 400, 500, np.inf],\n",
    "                      labels=['0-100', '101-200', '201-300', '301-400', '401-500', '500<'])\n",
    "    labels = test['classes'].unique().tolist()\n",
    "    labels.sort()\n",
    "    f = []\n",
    "    length = []\n",
    "    for k in labels:\n",
    "        cc = test.loc[test['classes']==k]\n",
    "        length.append(len(cc))\n",
    "        actual = cc.loc[:,'mosq_bins(t+1)']\n",
    "        predictions = cc.loc[:,'predictions']\n",
    "        f.append(mean_absolute_error(actual, predictions))\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.bar(labels,f)\n",
    "    for i, v in enumerate(f):\n",
    "        ax.text(i, v, str('%.2f'%(v)),rotation=30)\n",
    "        ax.text(i, v/2,'n = '+ str(length[i]),weight=\"bold\",ha='center')\n",
    "    plt.xlabel('Mosquito Group')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('MAE per Mosquito group \\n'+case)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a22928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_cdf(actual,prediction, case=''):\n",
    "    \"\"\"Prints the cdf of errors\n",
    "    Parameters\n",
    "    --------\n",
    "    actual : pd.Series\n",
    "        A Series with the actual class of each prediction\n",
    "        \n",
    "    predictions : pd.Series\n",
    "        A Series with the predicted class of each prediction\n",
    "        \n",
    "    case: str, optional\n",
    "        Title of the plot (default= '')\n",
    "\n",
    "    \"\"\"\n",
    "    error = np.abs(actual-prediction)\n",
    "    \n",
    "    a = np.sort(error.unique())\n",
    "    b = np.array(error)\n",
    "    cdf = np.zeros(len(a))\n",
    "    for k, val in enumerate(a):\n",
    "        mask_d = b <= val\n",
    "        cdf[k] = mask_d.sum()/ len(b)\n",
    "    plt.plot(a,cdf)\n",
    "    plt.grid()\n",
    "    plt.xlabel('abs(error)')\n",
    "    plt.ylabel('CDF')\n",
    "    plt.title('CDF of error \\n' + case)\n",
    "    plt.show() \n",
    "    \n",
    "    b = np.sort(error)\n",
    "    a = np.arange(1,len(error)+1) \n",
    "    cdf = np.zeros(len(a))\n",
    "    for k, val in enumerate(b):\n",
    "        cdf[k] = b[k]\n",
    "    plt.plot(a,cdf)\n",
    "    plt.grid()\n",
    "    plt.xlabel('Number of samples')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title('CDF of error \\n' + case)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c00821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_plots(train,test, target_type='class', case=''):\n",
    "    \"\"\"Prints plots about the performance of the model on the test set\n",
    "    \n",
    "    Parameters\n",
    "    --------        \n",
    "    test : Dataframe\n",
    "        A Dataframe with the actual and the predicted values on the train set\n",
    "    \n",
    "    model_type : str\n",
    "        Could be 'class_regression' or 'mosquito_regression' or 'classification'\n",
    "        \n",
    "    case: str, optional\n",
    "        Title of the plot (default= '')\n",
    "    \"\"\"\n",
    "    if target_type == 'class':\n",
    "        metrics(train, test)\n",
    "        plot_error_per_class(test, case)\n",
    "    else:\n",
    "        metrics(train, test, threshold=30)\n",
    "        plot_error_per_group(test['actual'],test['prediction'], case)\n",
    "        error_cdf(test['actual'],test['prediction'], case)\n",
    "    scatter_plot_error(test['actual'],test['prediction'], case)\n",
    "    plot_error_dist(test['actual'],test['prediction'], target_type, case)\n",
    "    plot_hist(test['actual'],test['prediction'], target_type, case)\n",
    "    plot_error_per_month(test, case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85ae4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(train, test, threshold=3):\n",
    "    \"\"\"Calculates the perfomance of the model on train and test set\n",
    "    Parameters\n",
    "    --------\n",
    "    train : Dataframe\n",
    "        A Dataframe with the actual and the predicted values on the train set\n",
    "        \n",
    "    test : Dataframe\n",
    "        A Dataframe with the actual and the predicted values on the train set\n",
    "        \n",
    "    threshold: int, optional\n",
    "        A threshold to calculate percentage of error < threshold (default= 3)\n",
    "\n",
    "    \"\"\"    \n",
    "    print('MAE on train set: ', mean_absolute_error(train['actual'], train['prediction']))\n",
    "\n",
    "    print('min prediction:',min(train['prediction']))\n",
    "    print('max prediction:',max(train['prediction']))\n",
    "    \n",
    "    print()\n",
    "\n",
    "    print('MAE on test set: ', mean_absolute_error(test['actual'], test['prediction']))\n",
    "    perc = ((np.abs(np.array(test['actual'])-np.array(test['prediction'])) < (threshold+0.5)).mean())*100\n",
    "    print('Error <= '+str(threshold)+':',\"%.2f\"%perc,'%')\n",
    "\n",
    "    print('min prediction:',min(test['prediction']))\n",
    "    print('max prediction:',max(test['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "vital-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_random_split(data, features, depth, estimators, step, filepath = '', date_col = 'dt_placement', case='', target_type = 'class', export=False):\n",
    "    \"\"\"Trains a model on random splitted data\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    data : dataframe\n",
    "        A dataframe containing the data\n",
    "    \n",
    "    features : lst\n",
    "        A list of features to use\n",
    "    \n",
    "    depth : int\n",
    "        The dpeth of the trees to construct\n",
    "        \n",
    "    estimators : int\n",
    "        The number of trees to construct\n",
    "        \n",
    "    step : int\n",
    "        The number of days for prediction\n",
    "        \n",
    "    filepath : srt, optional\n",
    "        The path of the file to export the results (default = '')\n",
    "        \n",
    "    date_col : str, optional\n",
    "        The name of the date column (default = 'dt_placement')\n",
    "    \n",
    "    case : str, optional\n",
    "        The title of case for the plot (default='')\n",
    "        \n",
    "    target_type : str, optional\n",
    "        The type of the target variable. Could be either 'class' or 'mosquito'. (default='class')\n",
    "    \n",
    "    export : boolean, optional\n",
    "        Export a csv with the feature importance and a csv with the test data (default = False)\n",
    "    \"\"\"\n",
    "    case = case + \" random validation\"\n",
    "    train_X,test_X,train_y,test_y = train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=0.20,random_state=0)\n",
    "    \n",
    "    train_X = train_X.reset_index(drop=True)\n",
    "    test_X = test_X.reset_index(drop=True)\n",
    "    train_y = train_y.reset_index(drop=True)\n",
    "    test_y = test_y.reset_index(drop=True)\n",
    "    \n",
    "    del train_X[date_col]\n",
    "    date = test_X[date_col]\n",
    "    del test_X[date_col]\n",
    "\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "    train_X1 = pca.fit_transform(train_X)\n",
    "    train_X1 = pd.DataFrame(train_X1)\n",
    "    train_X1.columns = ['PCA_1', 'PCA_2', 'PCA_3']\n",
    "    train_X = pd.concat([train_X,train_X1],axis=1)\n",
    "    \n",
    "\n",
    "    train_X = train_X[features]\n",
    "\n",
    "    test_X1 = pca.transform(test_X)\n",
    "    test_X1 = pd.DataFrame(test_X1)\n",
    "    test_X1.columns = ['PCA_1', 'PCA_2', 'PCA_3']\n",
    "    test_X = pd.concat([test_X,test_X1],axis=1)\n",
    "\n",
    "    test_X = test_X[features]\n",
    "\n",
    "    model = xgb.XGBRegressor(max_depth=depth,n_estimators = estimators,random_state=1)\n",
    "    model.fit(train_X, train_y)    \n",
    "    predictions = model.predict(test_X)\n",
    "    predictions =  np.round(predictions)      \n",
    "    predictions_train = model.predict(train_X)\n",
    "    predictions_train = np.round(predictions_train)\n",
    "    test_X['mosq_bins(t+1)'] = test_y\n",
    "    test_X[date_col] = date\n",
    "    test_X['dt_prediction'] = test_X[date_col] + datetime.timedelta(days=step)\n",
    "    test_X['predictions'] = predictions\n",
    "    test_X.loc[test_X['predictions']<0,'predictions'] = 0\n",
    "    test_X.loc[test_X['predictions']>data.iloc[:, -1].max(),'predictions'] = data.iloc[:, -1].max()\n",
    "    test_X['error'] = test_y - test_X['predictions']\n",
    "    test_X['abs(error)'] = np.abs(test_y- test_X['predictions'])\n",
    "#     mask = test_X['abs(error)'] < 3.5\n",
    "    train = {'actual': train_y, 'prediction':  predictions_train}\n",
    "    train = pd.DataFrame.from_dict(train)\n",
    "    \n",
    "    test = {'actual':test_X['mosq_bins(t+1)'], 'prediction':test_X['predictions'], 'dt_prediction':test_X['dt_prediction']}\n",
    "    test = pd.DataFrame.from_dict(test)\n",
    "    \n",
    "    validation_plots(train, test, target_type=target_type, case=case)  \n",
    "    plot_feature_importance(model.feature_importances_, train_X.columns, filepath, case, export)\n",
    "    \n",
    "    if export:\n",
    "        csv = filepath + case + '.csv'\n",
    "        test_X.to_csv(csv,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "duplicate-senator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_KFold(data, features, depth, estimators, target_type='class', date_col='dt_placement'):\n",
    "    \"\"\"Trains a model on KFold splitted data\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    data : dataframe\n",
    "        A dataframe containing the data\n",
    "    \n",
    "    features : lst\n",
    "        A list of features to use\n",
    "    \n",
    "    depth : int\n",
    "        The dpeth of the trees to construct\n",
    "        \n",
    "    estimators : int\n",
    "        The number of trees to construct\n",
    "        \n",
    "    target_type : str, optional\n",
    "        The type of the target variable. Could be either 'class' or 'mosquito'. (default='class')\n",
    "        \n",
    "    date_col : str, optional\n",
    "        The name of the date column (default = 'dt_placement')\n",
    "    \"\"\"\n",
    "\n",
    "    data = data.drop(date_col, 1)\n",
    "    data = data.sample(frac=1,random_state = 1)\n",
    "    kf = KFold(n_splits=10)\n",
    "    X = data.iloc[:,:-1]\n",
    "    y = data.iloc[:,-1]\n",
    "\n",
    "    trai = []\n",
    "    tes = []\n",
    "    perc = []\n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        train_X, test_X = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        train_y, test_y = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        train_X = train_X.reset_index(drop=True)\n",
    "        test_X = test_X.reset_index(drop=True)\n",
    "        train_y = train_y.reset_index(drop=True)\n",
    "        test_y = test_y.reset_index(drop=True)\n",
    "\n",
    "\n",
    "        pca = PCA(n_components=3)\n",
    "        train_X1 = pca.fit_transform(train_X)\n",
    "        train_X1 = pd.DataFrame(train_X1)\n",
    "        train_X1.columns = ['PCA_1', 'PCA_2', 'PCA_3']\n",
    "        train_X = pd.concat([train_X,train_X1],axis=1)\n",
    "\n",
    "        train_X = train_X[features]\n",
    "\n",
    "        test_X1 = pca.transform(test_X)\n",
    "        test_X1 = pd.DataFrame(test_X1)\n",
    "        test_X1.columns = ['PCA_1', 'PCA_2', 'PCA_3']\n",
    "        test_X = pd.concat([test_X,test_X1],axis=1)\n",
    "\n",
    "        test_X = test_X[features]\n",
    "\n",
    "        model = xgb.XGBRegressor(max_depth=depth,n_estimators = estimators,random_state=1)\n",
    "        model.fit(train_X, train_y)  \n",
    "\n",
    "        predictions = model.predict(test_X)\n",
    "        predictions =  np.round(predictions)\n",
    "        predictions[predictions<0] = 0\n",
    "        predictions[predictions>data.iloc[:, -1].max()] = data.iloc[:, -1].max()\n",
    "        mae_test = mean_absolute_error(test_y, predictions)  \n",
    "        tes.append(mae_test)\n",
    "\n",
    "        predictions_train = model.predict(train_X)\n",
    "        predictions_train = np.round(predictions_train)\n",
    "        predictions_train[predictions_train<0] = 0\n",
    "        predictions_train[predictions_train>data.iloc[:, -1].max()] = data.iloc[:, -1].max()\n",
    "        mae_train = mean_absolute_error(train_y, predictions_train)\n",
    "        trai.append(mae_train)\n",
    "\n",
    "        error = np.abs(test_y- predictions)\n",
    "        if target_type == 'class':\n",
    "            mask = error < 3.5\n",
    "        else:\n",
    "            mask = error < 30.5\n",
    "        perc.append(Average(mask))\n",
    "        \n",
    "    print('Average MAE on train set: ', Average(trai))\n",
    "    print('Average MAE on test set: ', Average(tes))\n",
    "    if target_type == 'class':\n",
    "        print('Average % of error < 3: ', Average(perc))\n",
    "    else:\n",
    "        print('Average % of error < 30: ', Average(perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "presidential-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "def operational_validation(data, features, depth, estimators, step, date, filepath ='', date_col='dt_placement', case='', target_type = 'class', export=False):\n",
    "    \"\"\"Trains a model on data of the previous months and evaluates on data of the next month iteratively.\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    data : dataframe\n",
    "        A dataframe containing the data\n",
    "    \n",
    "    features : lst\n",
    "        A list of features to use\n",
    "    \n",
    "    depth : int\n",
    "        The dpeth of the trees to construct\n",
    "        \n",
    "    estimators : int\n",
    "        The number of trees to construct\n",
    "        \n",
    "    step : int\n",
    "        The number of days for prediction\n",
    "        \n",
    "    date: str\n",
    "        The date to start the testing process from (format: YYYY-MM-DD)\n",
    "    \n",
    "    filepath : srt\n",
    "        The path of the file to export results (default ='')\n",
    "        \n",
    "    date_col : str, optional\n",
    "        The name of the date column (default = 'dt_placement')\n",
    "    \n",
    "    case : str, optional\n",
    "        The title of case for the plot (default ='')\n",
    "        \n",
    "    target_type : str, optional\n",
    "        The type of the target variable. Could be either 'class' or 'mosquito'. (default='class')\n",
    "    \n",
    "    export : boolean, optional\n",
    "        Export a csv with the feature importance and a csv with the test data (default=False)\n",
    "        \n",
    "    Raise\n",
    "    --------------\n",
    "    ValueError\n",
    "        If date > maximum date in the dataset\n",
    "        \n",
    "    \"\"\"\n",
    "    if (pd.to_datetime(date) > data['dt_placement'].max()):\n",
    "        raise ValueError('date argument given must be smaller than '+str(data['dt_placement'].max()))\n",
    "        \n",
    "    case = case + \" operational validation\"\n",
    "    df = pd.DataFrame()\n",
    "    months = data.loc[data['dt_placement']>pd.to_datetime(date),'dt_placement'].dt.to_period('M').unique()\n",
    "    months = months.strftime('%Y-%m')\n",
    "    months.sort()\n",
    "    for i in months:\n",
    "        date1 = i +'-01'\n",
    "        if i.split('-')[1]>='09':\n",
    "            date2 = i.split('-')[0] + '-' + str(int(i.split('-')[1]) + 1) + '-01'\n",
    "        else:\n",
    "            date2 = i.split('-')[0] + '-0' + str(int(i.split('-')[1]) + 1) + '-01'\n",
    "\n",
    "        train = data.loc[data[date_col] < pd.to_datetime(date1)]\n",
    "        del train[date_col]\n",
    "\n",
    "        test = data.loc[data[date_col] >= pd.to_datetime(date1)]\n",
    "        test = test.loc[test[date_col] < pd.to_datetime(date2)]\n",
    "\n",
    "        train = train.reset_index(drop=True)\n",
    "        test = test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "        date = test[date_col]\n",
    "        del test[date_col]\n",
    "\n",
    "        test_X, test_y = test.iloc[:, :-1], test.iloc[:, -1]\n",
    "        train_X, train_y = train.iloc[:, :-1], train.iloc[:, -1]\n",
    "\n",
    "\n",
    "        pca = PCA(n_components=3)\n",
    "        train_X1 = pca.fit_transform(train_X)\n",
    "        train_X1 = pd.DataFrame(train_X1)\n",
    "        train_X1.columns = ['PCA_1', 'PCA_2', 'PCA_3']\n",
    "        train_X = pd.concat([train_X,train_X1],axis=1)\n",
    "\n",
    "        train_X = train_X[features]\n",
    "\n",
    "        test_X1 = pca.transform(test_X)\n",
    "        test_X1 = pd.DataFrame(test_X1)\n",
    "        test_X1.columns = ['PCA_1', 'PCA_2', 'PCA_3']\n",
    "        test_X = pd.concat([test_X,test_X1],axis=1)\n",
    "\n",
    "        test_X = test_X[features]\n",
    "\n",
    "\n",
    "        model = xgb.XGBRegressor(max_depth=depth,n_estimators = estimators,random_state=1)\n",
    "        model.fit(train_X, train_y)         \n",
    "        predictions = model.predict(test_X)\n",
    "        predictions =  np.round(predictions)\n",
    "        mae_test = mean_absolute_error(test_y, predictions)               \n",
    "        predictions_train = model.predict(train_X)\n",
    "        predictions_train = np.round(predictions_train)\n",
    "        mae_train = mean_absolute_error(train_y, predictions_train)\n",
    "\n",
    "        test_X[date_col] = date\n",
    "        test_X['dt_prediction'] = test_X[date_col] + datetime.timedelta(days=step)\n",
    "        test_X['mosq_bins(t+1)'] = test_y\n",
    "        test_X['predictions'] = predictions\n",
    "        test_X.loc[test_X['predictions']<0,'predictions'] = 0\n",
    "        test_X.loc[test_X['predictions']>data.iloc[:, -1].max(),'predictions'] = data.iloc[:, -1].max()\n",
    "        test_X['error'] = test_X['mosq_bins(t+1)'] - test_X['predictions']\n",
    "        test_X['abs(error)'] = np.abs(test_X['mosq_bins(t+1)'] - test_X['predictions'])\n",
    "\n",
    "        df = pd.concat([df,test_X],axis=0)\n",
    "\n",
    "    train = {'actual': train_y, 'prediction':  predictions_train}\n",
    "    train = pd.DataFrame.from_dict(train)\n",
    "    \n",
    "    test = {'actual':df['mosq_bins(t+1)'], 'prediction':df['predictions'], 'dt_prediction':df['dt_prediction']}\n",
    "    test = pd.DataFrame.from_dict(test)\n",
    "    \n",
    "    validation_plots(train, test, target_type=target_type, case=case)\n",
    "    plot_feature_importance(model.feature_importances_, train_X.columns, filepath, case, export)\n",
    "    \n",
    "    if export:\n",
    "        csv = filepath + case + '.csv'\n",
    "        df.to_csv(csv,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "respected-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_with_flag(data, test_df, features, depth, estimators, step, filepath='', date_col='dt_placement', case='', target_type='class', export=False):\n",
    "    \"\"\"Trains a model on specifically splitted data into train and test sets\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    data : dataframe\n",
    "        A dataframe containing the data\n",
    "        \n",
    "    test_df : dataframe\n",
    "        A dataframe containing the test set\n",
    "    \n",
    "    features : lst\n",
    "        A list of features to use\n",
    "    \n",
    "    depth : int\n",
    "        The dpeth of the trees to construct\n",
    "        \n",
    "    estimators : int\n",
    "        The number of trees to construct\n",
    "        \n",
    "    step : int\n",
    "        The number of days for prediction\n",
    "        \n",
    "    filepath : srt, optional\n",
    "        The path of the file to export the results (default = '')\n",
    "    \n",
    "    date_col : str, optional\n",
    "        The name of the date column (default = 'dt_placement')\n",
    "    \n",
    "    case : str, optional\n",
    "        The title of case for the plot (default='')\n",
    "    \n",
    "    target_type : str, optional\n",
    "        The type of the target variable. Could be either 'class' or 'mosquito'. (default='class')\n",
    "    \n",
    "    export : boolean, optional\n",
    "        Export a csv with the feature importance and a csv with the test data (default=False)\n",
    "    \"\"\"\n",
    "    case = case + \" flag\"\n",
    "\n",
    "    train = data.reset_index(drop=True)\n",
    "    test = test_df.reset_index(drop=True)\n",
    "\n",
    "    date = test[date_col]\n",
    "    train = train.drop([date_col],axis=1)\n",
    "    test = test.drop([date_col],axis=1)\n",
    "    \n",
    "    test_X, test_y = test.iloc[:, :-1], test.iloc[:, -1]\n",
    "    train_X, train_y = train.iloc[:, :-1], train.iloc[:, -1]\n",
    "\n",
    "    pca = PCA(n_components=3)\n",
    "    train_X1 = pca.fit_transform(train_X)\n",
    "    train_X1 = pd.DataFrame(train_X1)\n",
    "    train_X1.columns = ['PCA_1', 'PCA_2', 'PCA_3']\n",
    "    train_X = pd.concat([train_X,train_X1],axis=1)\n",
    "\n",
    "    train_X = train_X[features]\n",
    "\n",
    "    test_X1 = pca.transform(test_X)\n",
    "    test_X1 = pd.DataFrame(test_X1)\n",
    "    test_X1.columns = ['PCA_1', 'PCA_2', 'PCA_3']\n",
    "    test_X = pd.concat([test_X,test_X1],axis=1)\n",
    "\n",
    "    test_X = test_X[features]\n",
    "    \n",
    "    neigh = NearestNeighbors(n_neighbors=21)\n",
    "    neigh.fit(train_X.iloc[:,:-1])\n",
    "    data_distance,_ = neigh.kneighbors(train_X.iloc[:,:-1])\n",
    "    arr1 = data_distance[:,1:].mean(axis=1)\n",
    "    \n",
    "    fig = plt.figure(figsize =(10, 7))\n",
    "    # Creating plot\n",
    "    plt.boxplot(arr1)\n",
    "    # show plot\n",
    "    plt.show()\n",
    "    \n",
    "    # finding the 1st quartile\n",
    "    q1 = np.quantile(arr1, 0.25)\n",
    "\n",
    "    # finding the 3rd quartile\n",
    "    q3 = np.quantile(arr1, 0.75)\n",
    "    med = np.median(arr1)\n",
    "\n",
    "    # finding the iqr region\n",
    "    iqr = q3-q1\n",
    "\n",
    "    # finding upper and lower whiskers\n",
    "    upper_bound = q3+(1.5*iqr)\n",
    "    lower_bound = q1-(1.5*iqr)\n",
    "    print(iqr, upper_bound, lower_bound)\n",
    "    \n",
    "    test_distance,_ = neigh.kneighbors(test_X.iloc[:,:-1])\n",
    "\n",
    "    model = xgb.XGBRegressor(max_depth=depth,n_estimators = estimators,random_state=1)\n",
    "    model.fit(train_X, train_y)    \n",
    "    predictions = model.predict(test_X)\n",
    "    predictions =  np.round(predictions)      \n",
    "    predictions_train = model.predict(train_X)\n",
    "    predictions_train = np.round(predictions_train)\n",
    "    test_X['mosq_bins(t+1)'] = test_y\n",
    "    test_X[date_col] = date\n",
    "    test_X['dt_prediction'] = test_X[date_col] + datetime.timedelta(days=step)\n",
    "    test_X['predictions'] = predictions\n",
    "    test_X.loc[test_X['predictions']<0,'predictions'] = 0\n",
    "    test_X.loc[test_X['predictions']>train_y.max(),'predictions'] = train_y.max()\n",
    "    test_X['error'] = test_y - test_X['predictions']\n",
    "    test_X['abs(error)'] = np.abs(test_y- test_X['predictions'])\n",
    "    mask = test_X['abs(error)'] < 3.5\n",
    "\n",
    "    train = {'actual': train_y, 'prediction':  predictions_train}\n",
    "    train = pd.DataFrame.from_dict(train)\n",
    "    \n",
    "    test = {'actual':test_X['mosq_bins(t+1)'], 'prediction':test_X['predictions'], 'dt_prediction':test_X['dt_prediction']}\n",
    "    test = pd.DataFrame.from_dict(test)\n",
    "    \n",
    "    validation_plots(train, test, target_type=target_type, case=case)\n",
    "    plot_feature_importance(model.feature_importances_, train_X.columns, filepath, case, export)\n",
    "    \n",
    "    test_X = pd.concat([test_X,pd.Series(test_distance[:,:20].mean(axis=1)).rename(\"mean_distance\")],axis=1)\n",
    "    test_X['flag'] = test_X['mean_distance'] > upper_bound\n",
    "    \n",
    "    corr = test_X[test_X['flag']==True]\n",
    "    print(\"num of flags: \",len(corr))\n",
    "    print('flags')\n",
    "    print(corr[['abs(error)','mean_distance']].corr())\n",
    "    print(corr['abs(error)'].mean())\n",
    "    print(corr.corr()['abs(error)'])\n",
    "    print('whole dataset')\n",
    "    print(test_X[['abs(error)','mean_distance']].corr())\n",
    "    print(test_X['abs(error)'].mean())\n",
    "    print(test_X.corr()['abs(error)'])\n",
    "    \n",
    "    plot_error_dist(test_X[test_X['flag']==True]['mosq_bins(t+1)'], test_X[test_X['flag']==True]['predictions'], target_type, \"on positive flags\")\n",
    "    plot_error_dist(test_X[test_X['flag']==False]['mosq_bins(t+1)'], test_X[test_X['flag']==False]['predictions'], target_type, \"on negative flags\")\n",
    "\n",
    "    if export:\n",
    "        csv = filepath + case + '.csv'\n",
    "        test_X.to_csv(csv,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
