{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c0372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_tree\n",
    "import geopandas as gpd\n",
    "from ipynb.fs.defs.Neural_Network_Module import Dataset, transformations_nn, prediction_nn, train_nn\n",
    "from ipynb.fs.defs.XGboost_Model_Module import  transformations_xgboost, predict_xgboost, train_xgboost\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac20bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    \"\"\"Calculates the average value of a list\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lst : list\n",
    "        A list of numbers\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    avg: float\n",
    "        The average value of the list\n",
    "    \"\"\"\n",
    "    avg = sum(lst) / len(lst)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a1360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_dist(actual, predictions, model_type, case=''):\n",
    "    \"\"\"Prints the error distribution plot\n",
    "    Parameters\n",
    "    --------\n",
    "    actual : pd.Series\n",
    "        A Series with the actual class of each prediction\n",
    "        \n",
    "    predictions : pd.Series\n",
    "        A Series with the predicted class of each prediction\n",
    "        \n",
    "    model_type : str\n",
    "        Could be 'class_regression' or 'mosquito_regression' or 'classification'\n",
    "    \n",
    "    case: str, optional\n",
    "        Title of the plot (default= '')\n",
    "    \"\"\"\n",
    "    error = np.abs(actual-predictions).tolist()\n",
    "    if model_type != 'mosquito_regression':\n",
    "        bins = np.arange(len(actual.unique())) - 0.5\n",
    "        plt.hist(error, bins)\n",
    "        plt.xticks(range(len(actual.unique())))\n",
    "    else:\n",
    "        plt.hist(error)\n",
    "    plt.xlabel('abs(error)')\n",
    "    plt.title('Error Distribution \\n' + case)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf1a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(actual, predictions, model_type, case=''):\n",
    "    \"\"\"Prints the histogram of the actual values and the predicted values\n",
    "    Parameters\n",
    "    --------\n",
    "    actual : pd.Series\n",
    "        A Series with the actual class of each prediction\n",
    "        \n",
    "    predictions : pd.Series\n",
    "        A Series with the predicted class of each prediction\n",
    "        \n",
    "    model_type : str\n",
    "        Could be 'class_regression' or 'mosquito_regression' or 'classification'\n",
    "    \n",
    "    case: str, optional\n",
    "        Title of the plot (default= '')\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,8)) \n",
    "    if model_type != 'mosquito_regression':\n",
    "        bins = np.arange(len(actual.unique())+1)-0.5\n",
    "        plt.hist(actual, bins=bins, alpha=0.5, label='actual')\n",
    "        plt.hist(predictions, bins=bins, alpha=0.5, label='prediction')\n",
    "        plt.xticks(range(len(actual.unique())))\n",
    "    else:\n",
    "        plt.hist(actual, alpha=0.5, label='actual')\n",
    "        plt.hist(predictions, alpha=0.5, label='prediction')\n",
    "    plt.legend()\n",
    "    plt.title('Histogram of actual vs predicted values \\n'+case)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d09320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_per_class(test, case=''):\n",
    "    \"\"\"Prints the error distribution per class plot\n",
    "    Parameters\n",
    "    --------\n",
    "    actual : lst\n",
    "        A list with the actual class of each prediction\n",
    "        \n",
    "    case: str, optional\n",
    "        Title of the plot (Area and mosquito genus) (default= '')\n",
    "    \"\"\"\n",
    "    labels = test.loc[:,'actual'].unique().tolist()\n",
    "    labels.sort()\n",
    "    f = []\n",
    "    length = []\n",
    "    for k in labels:\n",
    "        cc = test.loc[test['actual']==k]\n",
    "        length.append(len(cc))\n",
    "        actual = cc.loc[:,'actual']\n",
    "        predictions = cc.loc[:,'prediction']\n",
    "        mae_class = mean_absolute_error(actual, predictions)\n",
    "        f.append(mae_class)\n",
    "    labels = [str(int(e)) for e in labels]\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.bar(labels,f)\n",
    "    for i, v in enumerate(f):\n",
    "        ax.text(i, v, str('%.2f'%(v)), rotation=30)\n",
    "        ax.text(i, v/2,'n = '+ str(length[i]), weight=\"bold\", ha='center', rotation=90)\n",
    "    plt.xlabel('class')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('MAE per class ' + case)\n",
    "    plt.show()\n",
    "    \n",
    "    print('-----------|class error-MAE| difference-----------')\n",
    "    z = np.abs(f-mean_absolute_error(actual, predictions))\n",
    "    print('mean:',z.mean())\n",
    "    print('std:',z.std())\n",
    "    print('coefficient of variation (std/mean):',z.std()/z.mean())\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    print('----------normalized difference-------------')\n",
    "    min_val = min(z)\n",
    "    max_val = max(z)\n",
    "    z = (z - min_val) / (max_val-min_val)\n",
    "    print('mean:',z.mean())\n",
    "    print('std:',z.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add3936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_per_month(df, case=''):\n",
    "    \"\"\"Prints the error per month\n",
    "    Parameters\n",
    "    --------\n",
    "    df : dataframe\n",
    "        A dataframe containing the data\n",
    "    \n",
    "    case: str, optional\n",
    "        Title of the plot (Area and mosquito genus) (default= '')\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    labels = (df['dt_prediction'].dt.month).unique()\n",
    "    labels.sort()\n",
    "    labels = [str(e) for e in labels]\n",
    "    df['abs(error)'] = np.abs(df['actual']-df['prediction'])\n",
    "    f = df.groupby(by=[df['dt_prediction'].dt.month])['abs(error)'].mean().values\n",
    "    length = df.groupby(by=[df['dt_prediction'].dt.month])['dt_prediction'].count().values\n",
    "    ax.bar(labels,f)\n",
    "    for i, v in enumerate(f):\n",
    "        ax.text(i, v, str('%.2f'%(v)),rotation=30)\n",
    "        ax.text(i, v/2,'n = '+ str(length[i]),weight=\"bold\",ha='center', rotation=90)\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('Mean Absolute Error per month ' + case)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9be2083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot_error(actual, prediction, case=''):\n",
    "    \"\"\"Prints the error in relation with the distance of point from the train region\n",
    "    Parameters\n",
    "    --------\n",
    "    df : dataframe\n",
    "        A dataframe containing the data\n",
    "    \n",
    "    case: str, optional\n",
    "        Title of the plot (Area and mosquito genus) (default= '')\n",
    "    \"\"\"\n",
    "    # choose the input and output variables\n",
    "    x, y = actual, np.abs(actual-prediction)\n",
    "    plt.scatter(x, y)\n",
    "    plt.xlabel('Mosquito bins')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title('Scatterplot of error ' + case)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35bff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_per_group(actual,prediction,case=''):\n",
    "    \"\"\"Prints the error distribution plot\n",
    "    Parameters\n",
    "    --------\n",
    "    actual : pd.Series\n",
    "        A Series with the actual class of each prediction\n",
    "        \n",
    "    predictions : pd.Series\n",
    "        A Series with the predicted class of each prediction\n",
    "        \n",
    "    case: str, optional\n",
    "        Title of the plot (default= '')\n",
    "\n",
    "    \"\"\"\n",
    "    test = {'mosq_now':actual,'predictions':prediction}\n",
    "    test = pd.DataFrame(test)\n",
    "    test['classes'] = pd.cut(x=test['mosq_now'], bins=[-1, 100, 200, 300, 400, 500, np.inf],\n",
    "                      labels=['0-100', '101-200', '201-300', '301-400', '401-500', '500<'])\n",
    "    labels = test['classes'].unique().tolist()\n",
    "    labels.sort()\n",
    "    f = []\n",
    "    length = []\n",
    "    for k in labels:\n",
    "        cc = test.loc[test['classes']==k]\n",
    "        length.append(len(cc))\n",
    "        actual = cc.loc[:,'mosq_now']\n",
    "        predictions = cc.loc[:,'predictions']\n",
    "        f.append(mean_absolute_error(actual, predictions))\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.bar(labels,f)\n",
    "    for i, v in enumerate(f):\n",
    "        ax.text(i, v, str('%.2f'%(v)),rotation=30)\n",
    "        ax.text(i, v/2,'n = '+ str(length[i]),weight=\"bold\",ha='center', rotation=90)\n",
    "    plt.xlabel('Mosquito Group')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('MAE per Mosquito group \\n'+case)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_cdf(actual,prediction, case=''):\n",
    "    \"\"\"Prints the cdf of errors\n",
    "    Parameters\n",
    "    --------\n",
    "    actual : pd.Series\n",
    "        A Series with the actual class of each prediction\n",
    "        \n",
    "    predictions : pd.Series\n",
    "        A Series with the predicted class of each prediction\n",
    "        \n",
    "    case: str, optional\n",
    "        Title of the plot (default= '')\n",
    "\n",
    "    \"\"\"\n",
    "    error = np.abs(actual-prediction)\n",
    "    \n",
    "    a = np.sort(error.unique())\n",
    "    b = np.array(error)\n",
    "    cdf = np.zeros(len(a))\n",
    "    for k, val in enumerate(a):\n",
    "        mask_d = b <= val\n",
    "        cdf[k] = mask_d.sum()/ len(b)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.plot(a,cdf)\n",
    "    plt.grid()\n",
    "    plt.xlabel('abs(error)',fontsize=18)\n",
    "    plt.ylabel('CDF',fontsize=18)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    #plt.title('CDF of error \\n' + case)\n",
    "    plt.show() \n",
    "    \n",
    "    b = np.sort(error)\n",
    "    a = np.arange(1,len(error)+1) \n",
    "    cdf = np.zeros(len(a))\n",
    "    for k, val in enumerate(b):\n",
    "        cdf[k] = b[k]\n",
    "    plt.plot(a,cdf)\n",
    "    plt.grid()\n",
    "    plt.xlabel('Number of samples',fontsize=18)\n",
    "    plt.ylabel('Error',fontsize=18)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.title('CDF of error \\n' + case)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fc8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(train, test, threshold=3):\n",
    "    \"\"\"Calculates the perfomance of the model on train and test set\n",
    "    Parameters\n",
    "    --------\n",
    "    train : Dataframe\n",
    "        A Dataframe with the actual and the predicted values on the train set\n",
    "        \n",
    "    test : Dataframe\n",
    "        A Dataframe with the actual and the predicted values on the train set\n",
    "        \n",
    "    threshold: int, optional\n",
    "        A threshold to calculate percentage of error < threshold (default= 3)\n",
    "\n",
    "    \"\"\"    \n",
    "    print('MAE on train set: ', mean_absolute_error(train['actual'], train['prediction']))\n",
    "\n",
    "    print('min prediction:',min(train['prediction']))\n",
    "    print('max prediction:',max(train['prediction']))\n",
    "    \n",
    "    print()\n",
    "\n",
    "    print('MAE on test set: ', mean_absolute_error(test['actual'], test['prediction']))\n",
    "    perc = ((np.abs(test['actual']-test['prediction']) < (threshold+0.5)).mean())*100\n",
    "    print('Error <= '+str(threshold)+':',\"%.2f\"%perc,'%')\n",
    "\n",
    "    print('min prediction:',min(test['prediction']))\n",
    "    print('max prediction:',max(test['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f034d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(train, test, model_type, case=''):\n",
    "    \"\"\"Prints plots about the performance of the model on the test set\n",
    "    \n",
    "    Parameters\n",
    "    --------        \n",
    "    test : Dataframe\n",
    "        A Dataframe with the actual and the predicted values on the train set\n",
    "    \n",
    "    model_type : str\n",
    "        Could be 'class_regression' or 'mosquito_regression' or 'classification'\n",
    "        \n",
    "    case: str, optional\n",
    "        Title of the plot (default= '')\n",
    "    \"\"\"\n",
    "    if model_type != 'mosquito_regression':\n",
    "        metrics(train, test)\n",
    "        plot_error_per_class(test, case)\n",
    "    else:\n",
    "        metrics(train, test, threshold=30)\n",
    "        plot_error_per_group(test['actual'],test['prediction'], case)\n",
    "        error_cdf(test['actual'],test['prediction'], case)\n",
    "    scatter_plot_error(test['actual'],test['prediction'], case)\n",
    "    plot_error_dist(test['actual'],test['prediction'], model_type, case)\n",
    "    plot_hist(test['actual'],test['prediction'], model_type, case)\n",
    "    plot_error_per_month(test, case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab575b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nn(model, train, test=None, filepath = '', date_col = 'dt_placement', fi=False, case=''):\n",
    "    \n",
    "    if test is None:\n",
    "        train, test = train_test_split(train, test_size=0.2, random_state=3)\n",
    "        train = train.reset_index(drop=True)\n",
    "        test = test.reset_index(drop=True)\n",
    "        \n",
    "    train = train.drop([date_col],axis=1)    \n",
    "    date = test[date_col]\n",
    "    test = test.drop([date_col],axis=1)\n",
    "        \n",
    "    mosq_col = train.columns[-1]\n",
    "    max_val= train.iloc[:,-1].max()\n",
    "    \n",
    "    model_int = copy.deepcopy(model)\n",
    "    \n",
    "    features = None\n",
    "    if fi:\n",
    "        if model.embedding_data is not None:\n",
    "            columns = train.drop(columns=model.embedded_data.columns.tolist()).columns[:-1].tolist()\n",
    "            columns = columns+embedded_data.columns.tolist()\n",
    "            features = columns\n",
    "        else:\n",
    "            features = train.columns[:-1].tolist()\n",
    "    \n",
    "    train_X, train_y, test_X, test_y = transformations_nn(train, test = test, model_type = model.model_type, \n",
    "                                                       embedding_data = model.embedding_data,\n",
    "                                                       transformation_list = model.transformation_list)\n",
    "\n",
    "    training_set = Dataset(train_X, train_y)\n",
    "\n",
    "    testing_set = Dataset(test_X, test_y)\n",
    "\n",
    "    results_train, results_test, _ = train_nn(model = model_int, train_set = training_set, test_set = testing_set,\n",
    "                               features=features, max_val = max_val)\n",
    "    \n",
    "\n",
    "    test[date_col] = date\n",
    "    test['dt_prediction'] = test[date_col] + datetime.timedelta(days=15)\n",
    "    test['prediction'] = results_test['prediction']\n",
    "    test.loc[test['prediction']<0,'prediction'] = 0\n",
    "    test['error'] = test[mosq_col] - test['prediction']\n",
    "    test['abs(error)'] = np.abs(test[mosq_col] - test['prediction'])\n",
    "    \n",
    "    test = test.rename(columns={mosq_col:'actual'})\n",
    "\n",
    "    validation(results_train, test, model_type=model.model_type, case=case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a715cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_predictions_nn(model, train, test, env, filepath, date_col='dt_placement', case='', fi=False, export=False):\n",
    "    \"\"\" Trainning of the model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : FeedforwardNeuralNetModel\n",
    "        A FeedforwardNeuralNetModel model\n",
    "        \n",
    "    train : DataFrame\n",
    "        A Dataframe object with the train set\n",
    "        \n",
    "    test : DataFrame\n",
    "        A Dataframe object with the test set\n",
    "    \n",
    "    step : int\n",
    "        The number of days for prediction\n",
    "        \n",
    "    env : boolean\n",
    "        If true only enviromental features are used\n",
    "        \n",
    "    filepath : srt, optional\n",
    "        The path of the file to export the results\n",
    "        \n",
    "    transform_target : boolean, \n",
    "        If True, perofrms transformation of the target based on the model_type argument (default = False)\n",
    "        \n",
    "    learning_rate : int, optional\n",
    "        The learning_rate of the training process. (default = None)\n",
    "        \n",
    "    epochs : int, optional\n",
    "        The number of epochs for the training. (default = None)\n",
    "        \n",
    "    batch_size : int, optional\n",
    "        The size of each batch in each iteration. (default = None)\n",
    "        \n",
    "    ealry_stop : boolean, optional\n",
    "        If True, the trainning of the model may stop earlier than the epochs defined. (default = None)\n",
    "        \n",
    "    date_col : str, optional\n",
    "        The name of the date column (default = 'dt_placement')\n",
    "    \n",
    "    case : str, optional\n",
    "        The title of case for the plot (default='')\n",
    "    \n",
    "    export : boolean, optional\n",
    "        Export a csv with the feature importance and a csv with the test data (default=False)\n",
    "        \n",
    "    Returns\n",
    "    ----------        \n",
    "    output: DataFrame\n",
    "        A Dataframe containing the actual and the predicted values on the test set\n",
    "\n",
    "    \"\"\"    \n",
    "    date = test[date_col]\n",
    "    train = train.drop([date_col],axis=1)\n",
    "    test = test.drop([date_col],axis=1)\n",
    "    \n",
    "    mosq_col = train.columns[-1]\n",
    "    max_val= train.iloc[:,-1].max()\n",
    "    \n",
    "    features = None\n",
    "    if fi:\n",
    "        if model.embedding_data is not None:\n",
    "            columns = data.drop(columns=model.embedded_data.columns.tolist()).columns[:-1].tolist()\n",
    "            columns = columns+embedded_data.columns.tolist()\n",
    "            features = columns\n",
    "        else:\n",
    "            features = data.columns[:-1].tolist()\n",
    "    \n",
    "    model_int = copy.deepcopy(model)\n",
    "    \n",
    "    train_X, train_y, test_X, test_y = transformations_nn(train, test = test, model_type = model.model_type, \n",
    "                                                       embedding_data = model.embedding_data,\n",
    "                                                       transformation_list = model.transformation_list)\n",
    "\n",
    "    training_set = Dataset(train_X, train_y)\n",
    "\n",
    "    testing_set = Dataset(test_X, test_y)\n",
    "    \n",
    "    test_predict = prediction_nn(model, training_set, testing_set, features=features, max_val = max_val)\n",
    "            \n",
    "            \n",
    "    test[date_col] = date\n",
    "    test['dt_prediction'] = test[date_col] + datetime.timedelta(days = 15)\n",
    "    test['prediction'] = test_predict['prediction']\n",
    "    test.loc[test['prediction']<0,'prediction'] = 0\n",
    "    test.loc[test['prediction']>train.iloc[:, -1].max(),'prediction'] = train.iloc[:, -1].max()\n",
    "    test['entomological_features'] = not(env)\n",
    "    test['week'] = test['dt_prediction'].dt.isocalendar()['week']\n",
    "    test = test.sort_values(['dt_prediction'], ascending=True).reset_index(drop=True)\n",
    "    test = test.drop_duplicates(subset=['week', 'x', 'y'], keep='last').reset_index(drop=True)\n",
    "    \n",
    "    classes = test['prediction'].value_counts().sort_index()\n",
    "    \n",
    "    print(classes)\n",
    "    print()\n",
    "    print('Low risk category stations:',classes[classes.index<2].sum())\n",
    "    print('Medium risk category stations:',classes[(classes.index>1) & (classes.index<6)].sum())\n",
    "    print('High risk category stations:',classes[classes.index>5].sum())\n",
    "    \n",
    "    output = test[[date_col, 'dt_prediction', 'week', 'x', 'y', 'prediction', 'entomological_features']]\n",
    "    \n",
    "    if export:\n",
    "        csv_name = filepath + case + '.csv'\n",
    "        output.to_csv(csv_name,index=False)\n",
    "        geopandas_predictions(output,filepath,case)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f98e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_xgboost(model, train, test = None, date_col = 'dt_placement', filepath='', case = '', fi = False):\n",
    "    \"\"\"Trains a model on random splitted data\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    data : dataframe\n",
    "        A dataframe containing the data\n",
    "        \n",
    "    test_df : dataframe\n",
    "        A dataframe containing the prediction\n",
    "        \n",
    "    filepath : srt, optional\n",
    "        The path of the file to export the results\n",
    "        \n",
    "    date_col : str, optional\n",
    "        The name of the date column (default = 'dt_placement')\n",
    "        \n",
    "    case : str, optional\n",
    "        The title of case for the plot (default='')\n",
    "    \n",
    "    \"\"\"     \n",
    "    if test is None:\n",
    "        train, test = train_test_split(train, test_size=0.2, random_state=3)\n",
    "        train = train.reset_index(drop=True)\n",
    "        test = test.reset_index(drop=True)\n",
    "    \n",
    "    del train[date_col]\n",
    "    date = test[date_col]\n",
    "    del test[date_col]\n",
    "    \n",
    "    max_val= train.iloc[:,-1].max()\n",
    "    mosq_col = train.columns[-1]\n",
    "    \n",
    "    model_int = copy.deepcopy(model)\n",
    "    \n",
    "    train_X, train_y, test_X, test_y = transformations_xgboost(train, test = test, model_type = model.model_type,\n",
    "                                                               evaluation=False,\n",
    "                                                               transformation_list=model.transformation_list,\n",
    "                                                               embedding_data=model.embedding_data)\n",
    "\n",
    "    results_train, results_test = train_xgboost(model_int, train_X, train_y, test_X, test_y, max_val, fi)\n",
    "        \n",
    "    \n",
    "    test[date_col] = date\n",
    "    test['dt_prediction'] = test[date_col] + datetime.timedelta(days=15)\n",
    "    test['prediction'] = results_test['prediction']\n",
    "    test['error'] = test[mosq_col] - test['prediction']\n",
    "    test['abs(error)'] = np.abs(test[mosq_col] - test['prediction'])\n",
    "    \n",
    "    test = test.rename(columns={mosq_col:'actual'})\n",
    "    \n",
    "    validation(results_train, test, model_type=model.model_type, case=case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b1e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_predictions_xgboost(model, train, test, env, filepath, fi=False, date_col='dt_placement', case='',export=False):\n",
    "    \"\"\"Trains a model on random splitted data\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    data : dataframe\n",
    "        A dataframe containing the data\n",
    "        \n",
    "    test : dataframe\n",
    "        A dataframe containing the prediction\n",
    "    \n",
    "    features : lst\n",
    "        A list of features to use\n",
    "    \n",
    "    depth : int\n",
    "        The dpeth of the trees to construct\n",
    "        \n",
    "    estimators : int\n",
    "        The number of trees to construct\n",
    "        \n",
    "    env : boolean\n",
    "        If true only enviromental features are used\n",
    "        \n",
    "    filepath : srt, optional\n",
    "        The path of the file to export the results\n",
    "        \n",
    "    date_col : str, optional\n",
    "        The name of the date column (default = 'dt_placement')\n",
    "        \n",
    "    case : str, optional\n",
    "        The title of case for the plot (default='')\n",
    "    \n",
    "    export : boolean, optional\n",
    "        Export a csv with the feature importance and a csv with the test data (default=False)\n",
    "    \"\"\"\n",
    "\n",
    "    train = train.reset_index(drop=True)\n",
    "    test = test.reset_index(drop=True)\n",
    "\n",
    "    max_val= train.iloc[:,-1].max()\n",
    "    mosq_col = train.columns[-1]\n",
    "#     model_int = copy.deepcopy(model)\n",
    "    \n",
    "    del train[date_col]\n",
    "    date = test[date_col]\n",
    "    del test[date_col]\n",
    "    \n",
    "    \n",
    "    train_X, train_y, test_X, test_y = transformations_xgboost(train, test = test, model_type = model.model_type,\n",
    "                                                               evaluation=False,\n",
    "                                                               transformation_list=model.transformation_list,\n",
    "                                                               embedding_data=model.embedding_data)\n",
    "\n",
    "    results_test = predict_xgboost(model, train_X, train_y, test_X, test_y, max_val, fi)\n",
    "    \n",
    "    test[date_col] = date\n",
    "    test['dt_prediction'] = test[date_col] + datetime.timedelta(days=15)\n",
    "    test['prediction'] = results_test['prediction']\n",
    "    test['entomological_features'] = not(env)\n",
    "    test['week'] = test['dt_prediction'].dt.isocalendar()['week']\n",
    "    test = test.sort_values(['dt_prediction'], ascending=True).reset_index(drop=True)\n",
    "    test = test.drop_duplicates(subset=['week', 'x', 'y'], keep='last').reset_index(drop=True)\n",
    "    \n",
    "    classes = test['prediction'].value_counts().sort_index()\n",
    "    \n",
    "    print(classes)\n",
    "    print()\n",
    "    print('Low risk category stations:',classes[classes.index<2].sum())\n",
    "    print('Medium risk category stations:',classes[(classes.index>1) & (classes.index<6)].sum())\n",
    "    print('High risk category stations:',classes[classes.index>5].sum())\n",
    "    \n",
    "    output = test[[date_col, 'dt_prediction', 'week', 'x', 'y', 'prediction', 'entomological_features']]\n",
    "    \n",
    "    if export:\n",
    "        csv_name = filepath + case + '.csv'\n",
    "        output.to_csv(csv_name,index=False)\n",
    "        geopandas_predictions(output,filepath,case)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_predictions(predictions_env, predictions_entom, filepath='',case='', export=False):\n",
    "    \"\"\"Integrates the predictions with and without the entomolofical featues\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    predictions_env : dataframe\n",
    "        A dataframe containing the predictions based only on the enviromental features\n",
    "        \n",
    "    predictions_env : dataframe\n",
    "        A dataframe containing the predictions based on the enviromental and entomological features\n",
    "    \n",
    "    features : lst\n",
    "        A list of features to use\n",
    "        \n",
    "    filepath : srt, optional\n",
    "        The path of the file to export the results (default='')\n",
    "        \n",
    "    title : str, optional\n",
    "        The name of the case (default='')\n",
    "    \n",
    "    export : boolean, optional\n",
    "        Exports a csv with the predictions (default=False)\n",
    "        \n",
    "    \"\"\"\n",
    "    predictions = pd.concat([predictions_entom, predictions_env])\n",
    "    predictions = predictions.sort_values(['entomological_features'], ascending=False).reset_index(drop=True)\n",
    "    predictions = predictions.drop_duplicates(subset=['dt_placement', 'x', 'y'], keep='first').reset_index(drop=True)\n",
    "    predictions = predictions.drop_duplicates(subset=['week', 'x', 'y'], keep='first').reset_index(drop=True)\n",
    "\n",
    "    # Print risk classes for combined predictions\n",
    "    classes = predictions['prediction'].value_counts().sort_index()\n",
    "\n",
    "    print(classes)\n",
    "    print()\n",
    "    print('Low risk category stations:', classes[classes.index<2].sum())\n",
    "    print('Medium risk category stations:', classes[(classes.index>1) & (classes.index<6)].sum())\n",
    "    print('High risk category stations:', classes[classes.index>5].sum())\n",
    "\n",
    "    # Save combined predictions to csv\n",
    "    if export:\n",
    "        csv_name =  filepath + case + '.csv'\n",
    "        predictions.to_csv(csv_name,index=False)\n",
    "        geopandas_predictions(predictions,filepath,case)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c139613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_results(predictions_path, data, period=8, radius=1, long_column='x', lat_column='y', error_buffer=3):\n",
    "    \"\"\"Checks the accuracy of the predictions of the previous month.\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    predictions_path : str\n",
    "        A path to the file containing the predictions of a month\n",
    "        \n",
    "    data : dataframe\n",
    "        A dataframe containing the dates and the actual classes on each date\n",
    "        \n",
    "    period : int, optional\n",
    "        The period around a prediction that is acceptable to check for error (default = 8)\n",
    "        \n",
    "    radius : int or fload, optional\n",
    "        The distance (in Km) around a point to search for mosquito measurment (default = 1)\n",
    "        \n",
    "    long_column : str, optional\n",
    "            The name of the column with the longitude (default = 'x')\n",
    "        \n",
    "    lat_column : str, optional\n",
    "        The name of the column with the latitude (default = 'y')\n",
    "        \n",
    "    error_buffer : int, optional\n",
    "        The error buffer for cumpiting percentage of error (default = 3)\n",
    "        \n",
    "    \"\"\"\n",
    "    predictions = pd.read_csv(predictions_path)\n",
    "    predictions['dt_placement'] = pd.to_datetime(predictions['dt_placement'], format=\"%Y-%m-%d\")\n",
    "    predictions['dt_prediction'] = pd.to_datetime(predictions['dt_prediction'], format=\"%Y-%m-%d\")\n",
    "    actual = []\n",
    "    date_l = []\n",
    "    \n",
    "    radians_y = data.loc[:,lat_column].astype(float).apply(math.radians)\n",
    "    radians_x = data.loc[:,long_column].astype(float).apply(math.radians)\n",
    "    radians_data = pd.concat([radians_y,radians_x],axis=1)\n",
    "    radians_y = predictions.loc[:,lat_column].astype(float).apply(math.radians)\n",
    "    radians_x = predictions.loc[:,long_column].astype(float).apply(math.radians)\n",
    "    radians_predictions = pd.concat([radians_y,radians_x],axis=1)\n",
    "    distances = haversine_distances(radians_predictions,radians_data)*6371\n",
    "    \n",
    "    for i in range(len(predictions)):\n",
    "        indexes = np.where(distances[i,:] <= radius)[0].tolist()\n",
    "        data1 = data.loc[indexes,:].reset_index(drop=True)\n",
    "        y = np.nan\n",
    "        d = np.nan\n",
    "        if len(data1)>0:\n",
    "            date =  predictions.loc[i,'dt_prediction']\n",
    "            diff = ((data1['dt_placement'] + datetime.timedelta(days=15)) - date).dt.days\n",
    "            indexmin = diff.abs().idxmin()\n",
    "            y = data1.loc[indexmin,'mosq_now']\n",
    "            d = diff[indexmin]\n",
    "            diff = diff.drop(indexmin)\n",
    "            while np.isnan(y) and (len(diff) !=0):\n",
    "                indexmin = diff.abs().idxmin()\n",
    "                y = data1.loc[indexmin,'mosq_now']\n",
    "                d = diff[indexmin]\n",
    "                diff = diff.drop(indexmin)\n",
    "        actual.append(y)\n",
    "        date_l.append(d)\n",
    "    predictions.loc[:,'actual'] = actual\n",
    "    predictions.loc[:,'time_diff'] = date_l\n",
    "    \n",
    "    predictions = predictions.loc[np.abs(predictions['time_diff'])<period]\n",
    "    if len(predictions) != 0:\n",
    "        x = predictions['prediction']-predictions['actual']\n",
    "        print('Mean time difference in days:',predictions['time_diff'].mean())\n",
    "        print('-------------------')\n",
    "        print('Overall MAE:',np.abs(x).mean())\n",
    "        print('Overall % error <=' +str(error_buffer) +':', np.round(Average(np.abs(x) <= error_buffer)*100,2))\n",
    "        print('number of observations:', len(x))\n",
    "        print('-------------------')\n",
    "        ent = predictions.loc[predictions['entomological_features']==True]\n",
    "        if len(ent) != 0:\n",
    "            x = ent['prediction']-ent['actual']\n",
    "            print('MAE with entomological:',np.abs(x).mean())\n",
    "            print('% error <='+ str(error_buffer) +' with entomological:', np.round(Average(np.abs(x) <= error_buffer)*100,2))\n",
    "            print('number of observations:', len(x))\n",
    "            print('-------------------')\n",
    "        ent = predictions.loc[predictions['entomological_features']==False]\n",
    "        if len(ent) != 0:    \n",
    "            x = ent['prediction']-ent['actual']\n",
    "            print('MAE without entomological:',np.abs(x).mean())\n",
    "            print('% error <='+ str(error_buffer) +' without entomological:', np.round(Average(np.abs(x) <= error_buffer)*100,2))\n",
    "            print('number of observations:', len(x))\n",
    "            print('-------------------')\n",
    "    else:\n",
    "        print('No predictions with difference less than %d days' % period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5084a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_results2(predictions, data, period=8, radius=1, long_column ='x', lat_column ='y'):\n",
    "    \"\"\"Checks the accuracy of the predictions of the previous month.\n",
    "    \n",
    "    Parameters\n",
    "    --------\n",
    "    predictions_path : str\n",
    "        A path to the file containing the predictions of a month\n",
    "        \n",
    "    data : dataframe\n",
    "        A dataframe containing the dates and the actual classes on each date\n",
    "        \n",
    "    period : int, optional\n",
    "        The period around a prediction that is acceptable to check for error (default = 8)\n",
    "        \n",
    "    period : int or fload, optional\n",
    "        The distance (in Km) around a point to search for mosquito measurment (default = 1)\n",
    "        \n",
    "    long_column : str, optional\n",
    "            The name of the column with the longitude (default = 'x')\n",
    "        \n",
    "    lat_column : str, optional\n",
    "        The name of the column with the latitude (default = 'y')\n",
    "        \n",
    "    \"\"\"\n",
    "#     predictions = pd.read_csv(predictions_path)\n",
    "    predictions['dt_placement'] = pd.to_datetime(predictions['dt_placement'], format=\"%Y-%m-%d\")\n",
    "    predictions['dt_prediction'] = pd.to_datetime(predictions['dt_prediction'], format=\"%Y-%m-%d\")\n",
    "    actual = []\n",
    "    date_l = []\n",
    "    \n",
    "    radians_y = data.loc[:,lat_column].astype(float).apply(math.radians)\n",
    "    radians_x = data.loc[:,long_column].astype(float).apply(math.radians)\n",
    "    radians_data = pd.concat([radians_y,radians_x],axis=1)\n",
    "    radians_y = predictions.loc[:,lat_column].astype(float).apply(math.radians)\n",
    "    radians_x = predictions.loc[:,long_column].astype(float).apply(math.radians)\n",
    "    radians_predictions = pd.concat([radians_y,radians_x],axis=1)\n",
    "    distances = haversine_distances(radians_predictions,radians_data)*6371\n",
    "    \n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "#         data1 = data.loc[(data['x'] == predictions.loc[i,'x']) & (data['y'] == predictions.loc[i,'y'])]\n",
    "        indexes = np.where(distances[i,:] <= radius)[0].tolist()\n",
    "        data1 = data.loc[indexes,:].reset_index(drop=True)\n",
    "        y = np.nan\n",
    "        d = np.nan\n",
    "        if len(data1)>0:\n",
    "            date =  predictions.loc[i,'dt_prediction']\n",
    "            diff = ((data1['dt_placement'] + datetime.timedelta(days=15)) - date).dt.days\n",
    "            indexmin = diff.abs().idxmin()\n",
    "            y = data1.loc[indexmin,'mosq_now']\n",
    "            d = diff[indexmin]\n",
    "            diff = diff.drop(indexmin)\n",
    "            while np.isnan(y) and (len(diff) !=0):\n",
    "                indexmin = diff.abs().idxmin()\n",
    "                y = data1.loc[indexmin,'mosq_now']\n",
    "                d = diff[indexmin]\n",
    "                diff = diff.drop(indexmin)\n",
    "        actual.append(y)\n",
    "        date_l.append(d)\n",
    "    predictions.loc[:,'actual'] = actual\n",
    "    predictions.loc[:,'time_diff'] = date_l\n",
    "    \n",
    "    predictions = pd.merge(predictions, data, how='inner', left_on = [predictions['x'], predictions['y'], predictions['dt_placement']], right_on = [data['x'], data['y'], data['dt_placement']])\n",
    "    predictions = predictions.drop(columns=['key_0', 'key_1', 'key_2','dt_placement_y', 'x_y', 'y_y']).rename(columns={'x_x':'x', 'y_x':'y', 'dt_placement_x':'dt_placement'})\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce497707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geopandas_predictions(predictions,path,title):\n",
    "\n",
    "    shapefile_path = '../Datasets/Shapefiles/'+'/'.join(path.split('/')[2:4])+'/'+'_'.join(path.split('/')[2:4])+'_shapefile_2km.shp'\n",
    "    shapefile_path = shapefile_path.replace('//','/').replace('__','_')\n",
    "    grid_shp = gpd.read_file(shapefile_path, encoding=\"utf_8\")\n",
    "    grid_shp['x'] = round(grid_shp['x'], 6)\n",
    "    grid_shp['y'] = round(grid_shp['y'], 6)\n",
    "\n",
    "    predictions_grid = pd.merge(predictions[['x','y','prediction']], grid_shp[['x', 'y', 'geometry']], on=['x', 'y'], how='inner')\n",
    "    predictions_grid = predictions_grid.reset_index(drop=True)\n",
    "    predictions_grid = gpd.GeoDataFrame(predictions_grid, geometry='geometry')\n",
    "    csv_name =  path + 'Shapefiles/' + title + '.shp'\n",
    "    csv_name = csv_name.replace('//','/').replace('__','_')\n",
    "#     print(csv_name)\n",
    "    predictions_grid.to_file(csv_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
