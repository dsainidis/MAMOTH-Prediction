{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script preprocess the initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import BallTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filepath, date_col = 'dt_placement',long_col='x',lat_col='y'):\n",
    "    \"\"\"Reads the data out of an input file (.csv or .xls) \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str\n",
    "        The path of the file\n",
    "        \n",
    "    date_col : str, , optional\n",
    "        The name of the column with the date (default = 'dt_placement')\n",
    "        \n",
    "    long_col : str, , optional\n",
    "        The name of the column with the longitude (default = 'x')\n",
    "        \n",
    "    lat_col : str, , optional\n",
    "        The name of the column with the longitude (default = 'y')\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    data: dataframe\n",
    "        A dataframe created by the input file\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    NotImplementedError\n",
    "    If the input file is not .csv or .xls\n",
    "    \n",
    "    KeyError\n",
    "    If there is no column with 'date_col', 'long_col' or 'lat_col' name\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # reading the file by xlrd (pip install xlrd)\n",
    "        data = pd.read_excel(filepath)\n",
    "        data = data.replace('<Null>',np.NaN)\n",
    "    except:\n",
    "        try:\n",
    "            # reading as CSV file\n",
    "            data = pd.read_csv(filepath)\n",
    "            data = data.replace('<Null>',np.NaN)\n",
    "        except: \n",
    "            raise NotImplementedError(\"Sorry, give me a .csv or .xls file\")\n",
    "    \n",
    "    try:            \n",
    "        data[date_col] = pd.to_datetime(data[date_col], format=\"%Y-%m-%d\")\n",
    "        data[long_col] = round(data[long_col], 6)\n",
    "        data[lat_col] = round(data[lat_col], 6)\n",
    "    except: \n",
    "        raise KeyError(\"No date, longitude or latitude column with this name was found\")\n",
    "    print(data.columns)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_topological(data, filepath, long_column='x', lat_column='y', neighbors=1):\n",
    "    \"\"\"Adds the topological features of each observation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Dataframe\n",
    "        A dataframe containing all the EO data\n",
    "    \n",
    "    filepath : str\n",
    "        The path of the file with the topological info\n",
    "        \n",
    "    long_column : str, , optional\n",
    "        The name of the column with the longitude (default = 'x')\n",
    "        \n",
    "    lat_column : str, , optional\n",
    "        The name of the column with the latitude (default = 'y')\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    data: dataframe\n",
    "        A dataframe containing the topological info for each observation\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    KeyError\n",
    "    If the filepath is not valid\n",
    "    \"\"\"\n",
    "    try:\n",
    "        topological = pd.read_csv(filepath)\n",
    "    except: \n",
    "        raise KeyError(\"Sorry, give me a .csv valid file path.\")\n",
    "    topological[long_column] = round(topological[long_column], 6)\n",
    "    topological[lat_column] = round(topological[lat_column], 6)\n",
    "    topological['x_rad'] = topological[long_column].apply(lambda x: np.deg2rad(x))\n",
    "    topological['y_rad'] = topological[lat_column].apply(lambda x: np.deg2rad(x))\n",
    "    data['x_rad'] = data[long_column].apply(lambda x: np.deg2rad(x))\n",
    "    data['y_rad'] = data[lat_column].apply(lambda x: np.deg2rad(x))\n",
    "    ball = BallTree(topological[[\"y_rad\", \"x_rad\"]].values, metric='haversine')\n",
    "    distances, indices = ball.query(data[[\"y_rad\", \"x_rad\"]].values, k = 1)\n",
    "    distances = [(d * 6371).tolist()[0] for d in distances]\n",
    "    indices = indices.tolist()\n",
    "    indices = [i[0] for i in indices]\n",
    "    del data['x_rad']\n",
    "    del data['y_rad']\n",
    "    del topological['x_rad']\n",
    "    del topological['y_rad']\n",
    "    del topological[long_column]\n",
    "    del topological[lat_column]\n",
    "    data['neighbors'] = indices\n",
    "    data = pd.merge(data, topological, how='left',left_on = [data.neighbors], right_index=True)\n",
    "    del data['neighbors']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(dataframe,columns_list=[],columns_names = []):\n",
    "    \"\"\"Selects which columns to keep from the dataframe and optionally rename the columns \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        Dataframe to be transformed\n",
    "        \n",
    "    columns_list : list, optional\n",
    "        A list with the names of the columns to keep (default = a list containing all columns)\n",
    "    \n",
    "    columns_names : list, optional\n",
    "        A list with the new names of the columns (default = a list containing the running names)\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        A transformed dataframe\n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    KeyError\n",
    "    If the length of columns_list and columns_names do not match\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if len(columns_list) != 0:\n",
    "            dataframe = dataframe[columns_list]\n",
    "        if len(columns_names) != 0:\n",
    "            dataframe.columns = columns_names\n",
    "    except:\n",
    "        raise KeyError('The column list and the name list must be of same size')\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_dataset(dataframe,dupl_list=['x','y','dt_placement'],group_list=['x','y','dt_placement'],mosq_col='mosq_now'):\n",
    "    \"\"\"Removes the duplicates rows and aggragates observations needed\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        Dataframe to be transformed\n",
    "    \n",
    "    dupl_list : list\n",
    "        A list with the names of the columns for removing the duplicates upon them (default=['x','y','dt_placement'])\n",
    "        \n",
    "    group_list : list\n",
    "        A list with the names of the columns for grouping the duplicates upon them (default=['x','y','dt_placement'])\n",
    "    \n",
    "    mosq_col : str, optional\n",
    "        The name of the column with the mosquito number (default = 'mosq_now')\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        A transformed dataframe\n",
    "        \n",
    "    Raises\n",
    "    ------    \n",
    "    KeyError\n",
    "        If column name(s) given not in index\n",
    "    \"\"\"\n",
    "    \n",
    "    if (mosq_col not in dataframe.columns):\n",
    "        raise KeyError('Column(s) not in index')\n",
    "    if len(dupl_list) != 0:\n",
    "        for i in dupl_list:\n",
    "            if i not in dataframe.columns:\n",
    "                raise KeyError('Column(s) not in index')\n",
    "    dataframe.drop_duplicates(subset=dupl_list+[mosq_col], keep='first',inplace=True)\n",
    "    agg_dict = {mosq_col: lambda x: x.sum(min_count=1)}\n",
    "    col = [e for e in dataframe.columns if e not in [mosq_col]+group_list]\n",
    "    for i in col:\n",
    "        agg_dict[i]= 'first'\n",
    "    dataframe = dataframe.groupby(group_list).agg(agg_dict).reset_index()\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_data(data, col_list, long_column='x', lat_column='y'):\n",
    "    \"\"\"Fills the NaN values of columns based on longitude and latitude column\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: Dataframe\n",
    "        Dataframe to be transformed\n",
    "    \n",
    "    col_list : list\n",
    "        A list with the names of the columnsto complete\n",
    "        \n",
    "    long_column : str, , optional\n",
    "        The name of the column with the longitude (default = 'x')\n",
    "        \n",
    "    lat_column : str, , optional\n",
    "        The name of the column with the latitude (default = 'y')\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    data: Dataframe\n",
    "        A dataframe with filled nan values\n",
    "        \n",
    "    Raises\n",
    "    ------    \n",
    "    KeyError\n",
    "        If column name(s) given not in index\n",
    "    \"\"\"\n",
    "    for i in col_list+[long_column,lat_column]:\n",
    "        if i not in data.columns:\n",
    "            raise KeyError('Column(s) not in index')\n",
    "    stations = data[[long_column,lat_column]+col_list].drop_duplicates(subset=[long_column,lat_column])\n",
    "    data = data.drop(columns=col_list)\n",
    "    data = pd.merge(data, stations, how='left',left_on = [data[long_column],data[lat_column]],right_on = [stations[long_column],stations[lat_column]])\n",
    "    data = data.drop(columns=['key_0','key_1',long_column+'_y',lat_column+'_y'])\n",
    "    data = data.rename(columns={long_column+'_x':long_column, lat_column+'_x':lat_column})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_dataset(dataframe,fill_list):\n",
    "    \"\"\"Fills the NaN values of columns specified with spesific values\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        Dataframe to be transformed\n",
    "    \n",
    "    dupl_list : dict\n",
    "        A dictionairy with the names of the columns and the value for NaN to complete\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        A transformed dataframe with filled nan values\n",
    "        \n",
    "    Raises\n",
    "    ------    \n",
    "    KeyError\n",
    "        If column name(s) given not in index\n",
    "    \"\"\"\n",
    "    for i in list(fill_list.keys()):\n",
    "        if i not in dataframe.columns:\n",
    "            raise KeyError('Column(s) not in index')\n",
    "        else:\n",
    "            dataframe[i] = dataframe[i].fillna(fill_list[i])\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_diff(data, long_column='x', lat_column='y', date_column='dt_placement'):\n",
    "    \"\"\"Creates a list with the time difference between two consecutive observations of each station\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: Dataframe\n",
    "        The dataframe contaning the number of mosquitoes\n",
    "\n",
    "    long_column : str, optional\n",
    "        The name of the column with the longitude (default = 'x')\n",
    "        \n",
    "    lat_column : str, optional\n",
    "        The name of the column with the latitude (default = 'y')\n",
    "\n",
    "    date_column : str, optional\n",
    "        The name of the column containing the date of observations (default = 'dt_placement')\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    time_diff: lst\n",
    "        A list containing the distance of each observation from the next one\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    KeyError\n",
    "    If not some of the columns are included in the dataframe\n",
    "    \"\"\"\n",
    "    if (long_column not in data.columns or lat_column not in data.columns or date_column not in data.columns):\n",
    "        raise KeyError('Column(s) not in index')\n",
    "    time_diff = []\n",
    "    data = data.dropna(subset=['mosq_now'])\n",
    "    stations = data.loc[:, [long_column, lat_column]].drop_duplicates().reset_index(drop=True)\n",
    "    for i in range(len(stations)):\n",
    "        data2 = data.loc[(data[long_column] == stations.loc[i,long_column]) & (data[lat_column] == stations.loc[i,lat_column])]\n",
    "        data2 = data2.sort_values(by=[date_column], ascending=[True])\n",
    "        data2.reset_index(drop=True,inplace=True)\n",
    "        for j in range(len(data2)):\n",
    "            data3 = data2.loc[data2[date_column].dt.year == data2[date_column][j].year]\n",
    "            x = data3[date_column][j] < data3[date_column]\n",
    "            y = x[x==True]\n",
    "            if len(y) == 0:\n",
    "                y = np.nan\n",
    "            else:\n",
    "                y = x[x==True].idxmin()\n",
    "                y = np.abs((data2[date_column][j] - data2[date_column][y]).days)\n",
    "            time_diff.append(y)\n",
    "    time_diff = [x for x in time_diff if str(x) != 'nan']\n",
    "    time_diff.sort()\n",
    "    print('Length: ',len(time_diff))\n",
    "    return time_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdf_plot(d, d_length):\n",
    "    \"\"\"Plots the cdf of the vector of days of difference between the observations of each station.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    d : Vector\n",
    "        A vector containing the days of differnece\n",
    "\n",
    "    d_length : int\n",
    "        The length of the vector d\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    step : lst\n",
    "        The optimal step in days in order to catch at least 80% of the observations days difference\n",
    "    \"\"\"\n",
    "    a = np.linspace(min(d), max(d), 100)\n",
    "    cdf = np.zeros(len(a))\n",
    "    for k, val in enumerate(a):\n",
    "        mask_d = d < val\n",
    "        cdf[k] = mask_d.sum()/ d_length\n",
    "\n",
    "    plt.plot(a,cdf)\n",
    "    plt.grid()\n",
    "    plt.xlabel('time difference')\n",
    "    plt.ylabel('CDF')\n",
    "    plt.show()\n",
    "    idx = (np. abs(cdf - 0.8)). argmin()\n",
    "    return np.round(a[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
