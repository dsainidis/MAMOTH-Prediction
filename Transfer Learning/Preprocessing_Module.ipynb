{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script preprocess the initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import BallTree\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filepath, date_col = 'dt_placement',long_col='x',lat_col='y'):\n",
    "    \"\"\"Reads the data out of an input file (.csv or .xls) \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str\n",
    "        The path of the file\n",
    "        \n",
    "    date_col : str, , optional\n",
    "        The name of the column with the date (default = 'dt_placement')\n",
    "        \n",
    "    long_col : str, , optional\n",
    "        The name of the column with the longitude (default = 'x')\n",
    "        \n",
    "    lat_col : str, , optional\n",
    "        The name of the column with the longitude (default = 'y')\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    data: dataframe\n",
    "        A dataframe created by the input file\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    NotImplementedError\n",
    "    If the input file is not .csv or .xls\n",
    "    \n",
    "    KeyError\n",
    "    If there is no column with 'date_col', 'long_col' or 'lat_col' name\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # reading the file by xlrd (pip install xlrd)\n",
    "        data = pd.read_excel(filepath)\n",
    "        data = data.replace('<Null>',np.NaN)\n",
    "    except:\n",
    "        try:\n",
    "            # reading as CSV file\n",
    "            data = pd.read_csv(filepath)\n",
    "            data = data.replace('<Null>',np.NaN)\n",
    "        except: \n",
    "            raise NotImplementedError(\"Sorry, give me a .csv or .xls file\")\n",
    "    \n",
    "    try:            \n",
    "        data[date_col] = pd.to_datetime(data[date_col], format=\"%Y-%m-%d\")\n",
    "        data[long_col] = round(data[long_col], 6)\n",
    "        data[lat_col] = round(data[lat_col], 6)\n",
    "    except: \n",
    "        raise KeyError(\"No date, longitude or latitude column with this name was found\")\n",
    "    data.columns = data.columns.str.replace(r'_new', '')\n",
    "    print(data.columns)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_topological(data, filepath, long_column='x', lat_column='y', neighbors=1):\n",
    "    \"\"\"Adds the topological features of each observation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Dataframe\n",
    "        A dataframe containing all the EO data\n",
    "    \n",
    "    filepath : str\n",
    "        The path of the file with the topological info\n",
    "        \n",
    "    long_column : str, , optional\n",
    "        The name of the column with the longitude (default = 'x')\n",
    "        \n",
    "    lat_column : str, , optional\n",
    "        The name of the column with the latitude (default = 'y')\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    data: dataframe\n",
    "        A dataframe containing the topological info for each observation\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    KeyError\n",
    "    If the filepath is not valid\n",
    "    \"\"\"\n",
    "    try:\n",
    "        topological = pd.read_csv(filepath)\n",
    "    except: \n",
    "        raise KeyError(\"Sorry, give me a .csv valid file path.\")\n",
    "    topological[long_column] = round(topological[long_column], 6)\n",
    "    topological[lat_column] = round(topological[lat_column], 6)\n",
    "    topological['x_rad'] = topological[long_column].apply(lambda x: np.deg2rad(x))\n",
    "    topological['y_rad'] = topological[lat_column].apply(lambda x: np.deg2rad(x))\n",
    "    data['x_rad'] = data[long_column].apply(lambda x: np.deg2rad(x))\n",
    "    data['y_rad'] = data[lat_column].apply(lambda x: np.deg2rad(x))\n",
    "    ball = BallTree(topological[[\"y_rad\", \"x_rad\"]].values, metric='haversine')\n",
    "    distances, indices = ball.query(data[[\"y_rad\", \"x_rad\"]].values, k = 1)\n",
    "    distances = [(d * 6371).tolist()[0] for d in distances]\n",
    "    indices = indices.tolist()\n",
    "    indices = [i[0] for i in indices]\n",
    "    del data['x_rad']\n",
    "    del data['y_rad']\n",
    "    del topological['x_rad']\n",
    "    del topological['y_rad']\n",
    "    del topological[long_column]\n",
    "    del topological[lat_column]\n",
    "    data['neighbors'] = indices\n",
    "    data = pd.merge(data, topological, how='left',left_on = [data.neighbors], right_index=True)\n",
    "    del data['neighbors']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_landcover(data, filepath, long_column='x', lat_column='y', date_column='dt_placement', neighbors=1):\n",
    "    \"\"\"Adds the landcover features of each observation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Dataframe\n",
    "        A dataframe containing all the EO data\n",
    "    \n",
    "    filepath : str\n",
    "        The path of the file with the landcover info\n",
    "        \n",
    "    long_column : str, , optional\n",
    "        The name of the column with the longitude (default = 'x')\n",
    "        \n",
    "    lat_column : str, , optional\n",
    "        The name of the column with the latitude (default = 'y')\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    data: dataframe\n",
    "        A dataframe containing the landcover info for each observation\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    KeyError\n",
    "    If the filepath is not valid\n",
    "    \"\"\"\n",
    "    try:\n",
    "        landcover = pd.read_csv(filepath)\n",
    "    except: \n",
    "        raise KeyError(\"Sorry, give me a .csv valid file path.\")\n",
    "    landcover[long_column] = round(landcover[long_column], 6)\n",
    "    landcover[lat_column] = round(landcover[lat_column], 6)\n",
    "    landcover['x_rad'] = landcover[long_column].apply(lambda x: np.deg2rad(x))\n",
    "    landcover['y_rad'] = landcover[lat_column].apply(lambda x: np.deg2rad(x))\n",
    "    data['x_rad'] = data[long_column].apply(lambda x: np.deg2rad(x))\n",
    "    data['y_rad'] = data[lat_column].apply(lambda x: np.deg2rad(x))\n",
    "    ball = BallTree(landcover[[\"y_rad\", \"x_rad\"]].values, metric='haversine')\n",
    "    distances, indices = ball.query(data[[\"y_rad\", \"x_rad\"]].values, k = 1)\n",
    "    distances = [(d * 6371).tolist()[0] for d in distances]\n",
    "    indices = indices.tolist()\n",
    "    indices = [i[0] for i in indices]\n",
    "    del data['x_rad']\n",
    "    del data['y_rad']\n",
    "    del landcover['x_rad']\n",
    "    del landcover['y_rad']\n",
    "    del landcover[long_column]\n",
    "    del landcover[lat_column]\n",
    "    data['neighbors'] = indices\n",
    "    data = pd.merge(data, landcover, how='left',left_on = [data.neighbors], right_index=True)\n",
    "    del data['neighbors']\n",
    "    landcover_cols = landcover.columns.tolist()\n",
    "    data['landcover'] = data[date_column].apply(lambda x: str(x.year)+'_01_01_LC_Type1' if x.year <=2021 else '2021_01_01_LC_Prop1')\n",
    "    data['landcover'] = data.apply(lambda x: x[x['landcover']], axis=1)\n",
    "    data = data.drop(columns=landcover_cols)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(dataframe,columns_list=[],columns_names = []):\n",
    "    \"\"\"Selects which columns to keep from the dataframe and optionally rename the columns \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        Dataframe to be transformed\n",
    "        \n",
    "    columns_list : list, optional\n",
    "        A list with the names of the columns to keep (default = a list containing all columns)\n",
    "    \n",
    "    columns_names : list, optional\n",
    "        A list with the new names of the columns (default = a list containing the running names)\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        A transformed dataframe\n",
    "        \n",
    "    Raises\n",
    "    ------\n",
    "    KeyError\n",
    "    If the length of columns_list and columns_names do not match\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if len(columns_list) != 0:\n",
    "            dataframe = dataframe[columns_list]\n",
    "        if len(columns_names) != 0:\n",
    "            dataframe.columns = columns_names\n",
    "    except:\n",
    "        raise KeyError('The column list and the name list must be of same size')\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_dataset(dataframe,dupl_list=['x','y','dt_placement'],group_list=['x','y','dt_placement'],mosq_col='mosq_now'):\n",
    "    \"\"\"Removes the duplicates rows and aggragates observations needed\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        Dataframe to be transformed\n",
    "    \n",
    "    dupl_list : list\n",
    "        A list with the names of the columns for removing the duplicates upon them (default=['x','y','dt_placement'])\n",
    "        \n",
    "    group_list : list\n",
    "        A list with the names of the columns for grouping the duplicates upon them (default=['x','y','dt_placement'])\n",
    "    \n",
    "    mosq_col : str, optional\n",
    "        The name of the column with the mosquito number (default = 'mosq_now')\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        A transformed dataframe\n",
    "        \n",
    "    Raises\n",
    "    ------    \n",
    "    KeyError\n",
    "        If column name(s) given not in index\n",
    "    \"\"\"\n",
    "    \n",
    "    if (mosq_col not in dataframe.columns):\n",
    "        raise KeyError('Column(s) not in index')\n",
    "    if len(dupl_list) != 0:\n",
    "        for i in dupl_list:\n",
    "            if i not in dataframe.columns:\n",
    "                raise KeyError('Column(s) not in index')\n",
    "    dataframe.drop_duplicates(subset=dupl_list+[mosq_col], keep='first',inplace=True)\n",
    "    agg_dict = {mosq_col: lambda x: x.sum(min_count=1)}\n",
    "    col = [e for e in dataframe.columns if e not in [mosq_col]+group_list]\n",
    "    for i in col:\n",
    "        agg_dict[i]= 'first'\n",
    "    dataframe = dataframe.groupby(group_list).agg(agg_dict).reset_index()\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_data(data, col_list, long_column='x', lat_column='y'):\n",
    "    \"\"\"Fills the NaN values of columns based on longitude and latitude column\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: Dataframe\n",
    "        Dataframe to be transformed\n",
    "    \n",
    "    col_list : list\n",
    "        A list with the names of the columnsto complete\n",
    "        \n",
    "    long_column : str, , optional\n",
    "        The name of the column with the longitude (default = 'x')\n",
    "        \n",
    "    lat_column : str, , optional\n",
    "        The name of the column with the latitude (default = 'y')\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    data: Dataframe\n",
    "        A dataframe with filled nan values\n",
    "        \n",
    "    Raises\n",
    "    ------    \n",
    "    KeyError\n",
    "        If column name(s) given not in index\n",
    "    \"\"\"\n",
    "    for i in col_list+[long_column,lat_column]:\n",
    "        if i not in data.columns:\n",
    "            raise KeyError('Column(s) not in index')\n",
    "    stations = data[[long_column,lat_column]+col_list].drop_duplicates(subset=[long_column,lat_column])\n",
    "    data = data.drop(columns=col_list)\n",
    "    data = pd.merge(data, stations, how='left',left_on = [data[long_column],data[lat_column]],right_on = [stations[long_column],stations[lat_column]])\n",
    "    data = data.drop(columns=['key_0','key_1',long_column+'_y',lat_column+'_y'])\n",
    "    data = data.rename(columns={long_column+'_x':long_column, lat_column+'_x':lat_column})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_dataset(dataframe,fill_list):\n",
    "    \"\"\"Fills the NaN values of columns specified with spesific values\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        Dataframe to be transformed\n",
    "    \n",
    "    dupl_list : dict\n",
    "        A dictionairy with the names of the columns and the value for NaN to complete\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        A transformed dataframe with filled nan values\n",
    "        \n",
    "    Raises\n",
    "    ------    \n",
    "    KeyError\n",
    "        If column name(s) given not in index\n",
    "    \"\"\"\n",
    "    for i in list(fill_list.keys()):\n",
    "        if i not in dataframe.columns:\n",
    "            raise KeyError('Column(s) not in index')\n",
    "        else:\n",
    "            dataframe[i] = dataframe[i].fillna(fill_list[i])\n",
    "    return dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
